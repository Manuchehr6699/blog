/*
SQLyog Ultimate v12.14 (64 bit)
MySQL - 10.3.13-MariaDB : Database - blog
*********************************************************************
*/

/*!40101 SET NAMES utf8 */;

/*!40101 SET SQL_MODE=''*/;

/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;
CREATE DATABASE /*!32312 IF NOT EXISTS*/`blog` /*!40100 DEFAULT CHARACTER SET utf8 */;

USE `blog`;

/*Table structure for table `post` */

DROP TABLE IF EXISTS `post`;

CREATE TABLE `post` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `title` varchar(255) NOT NULL,
  `content` text NOT NULL,
  `published_at` datetime NOT NULL,
  `published_by` int(11) DEFAULT NULL,
  `status` tinyint(2) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=13 DEFAULT CHARSET=utf8;

/*Data for the table `post` */

insert  into `post`(`id`,`title`,`content`,`published_at`,`published_by`,`status`) values 
(1,'Почему const не ускоряет код на С/C++?','Несколько месяцев назад я упомянул в одном посте, что это миф, будто бы const помогает включать оптимизации компилятора в C и C++. Я решил, что нужно объяснить это утверждение, особенно потому, что раньше я сам верил в этот миф. Начну с теории и искусственных примеров, а затем перейду к экспериментам и бенчмаркам на реальной кодовой базе — SQLite.\r\nЧтобы выполнить printf(), процессор должен через указатель извлечь из памяти значение *x. Очевидно, что выполнение constByArg() может слегка ускориться, поскольку компилятору известно, что *x является константой, поэтому нет нужды загружать её значение снова, после того как это сделала constFunc(). Правильно? Давайте посмотрим ассемблерный код, сгенерированный GCC со включёнными оптимизациями:\r\nЕдинственное различие между ассемблерным кодом, сгенерированным для byArg() и constByArg(), заключается в том, что у constByArg() есть call constFunc@PLT, как в исходном коде. Сам const не привносит никаких различий.\r\n\r\nЛадно, это был GCC. Возможно, нам нужен компилятор поумнее. Скажем, Clang.\r\nС одной стороны, я не думаю, что на практике это часто применяется в С++-коде. С другой стороны, чтобы действительно была разница, программист должен делать предположения, которые недоступны компилятору, поскольку они не гарантированы языком.\r\n\r\nЭксперимент с SQLite3\r\n\r\nХватит теории и надуманных примеров. Какое влияние оказывает const на настоящую кодовую базу? Я решил провести эксперимент с БД SQLite (версия 3.30.0), потому что:\r\n\r\nВ ней используется const.\r\nЭто нетривиальная кодовая база (свыше 200 KLOC).\r\nВ качестве базы данных она включает в себя ряд механизмов, начиная с обработки строковых значений и заканчивая преобразованием чисел в дату.\r\nЕё можно протестировать с помощью нагрузки, ограниченной по процессору.\r\n\r\nКроме того, автор и программисты, участвующие в разработке, уже потратили годы на улучшение производительности, так что можно предположить, что они не пропустили ничего очевидного.\r\n\r\nПодготовка\r\n\r\nЯ сделал две копии исходного кода. Одну скомпилировал в обычном режиме, а вторую предварительно обработал с помощью хака, чтобы превратить const в холостую команду:\r\n\r\n#define const\r\n\r\n(GNU) sed может добавить это поверх каждого файла с помощью команды sed -i \'1i#define const\' *.c *.h.\r\n\r\nSQLite всё немного усложняет, с помощью скриптов генерируя код в ходе сборки. К счастью, компиляторы вносят много помех при смешивании кода с const и без const, так что это можно было сразу заметить и настроить скрипты для добавления моего анти-const кода.\r\n\r\nПрямое сравнение скомпилированных кодов не имеет смысла, поскольку мелкое изменение может повлиять на всю схему памяти, что приведёт к изменению указателей и вызовов функций во всём коде. Поэтому я снял дизассемблерный слепок (objdump -d libSQLite3.so.0.8.6) в виде размера бинарника и мнемонического названия каждой инструкции. Например, эта функция:\r\n\r\n000000000005d570 <SQLite3_blob_read>:\r\n   5d570:       4c 8d 05 59 a2 ff ff    lea    -0x5da7(%rip),%r8        # 577d0 <SQLite3BtreePayloadChecked>\r\n   5d577:       e9 04 fe ff ff          jmpq   5d380 <blobReadWrite>\r\n   5d57c:       0f 1f 40 00             nopl   0x0(%rax)\r\n\r\nПревращается в:\r\n\r\nSQLite3_blob_read   7lea 5jmpq 4nopl\r\n\r\nПри компилировании я не менял сборочные настройки SQLite.\r\n\r\nАнализ скомпилированного кода\r\n\r\nУ libSQLite3.so версия с const занимала 4 740 704 байтов, примерно на 0,1 % больше версии без const с её 4 736 712 байтами. В обоих случаях было экспортировано 1374 функции (не считая низкоуровневые вспомогательные функции в PLT), и у 13 были какие-нибудь различия в слепках.\r\n\r\nНекоторые изменения были связаны с хаком предварительной обработки. К примеру, вот одна из изменившихся функций (я убрал некоторые определения, характерные для SQLite):\r\n\r\n#define LARGEST_INT64  (0xffffffff|(((int64_t)0x7fffffff)<<32))\r\n#define SMALLEST_INT64 (((int64_t)-1) - LARGEST_INT64)\r\n\r\nstatic int64_t doubleToInt64(double r){\r\n  /*\r\n  ** Many compilers we encounter do not define constants for the\r\n  ** minimum and maximum 64-bit integers, or they define them\r\n  ** inconsistently.  And many do not understand the \"LL\" notation.\r\n  ** So we define our own static constants here using nothing\r\n  ** larger than a 32-bit integer constant.\r\n  */\r\n  static const int64_t maxInt = LARGEST_INT64;\r\n  static const int64_t minInt = SMALLEST_INT64;\r\n\r\n  if( r<=(double)minInt ){\r\n    return minInt;\r\n  }else if( r>=(double)maxInt ){\r\n    return maxInt; \r\n  }else{\r\n    return (int64_t)r;\r\n  }\r\n}\r\n\r\nЕсли убрать const, то эти константы превращаются в static-переменные. Не понимаю, зачем кому-то, кого не волнуют const, делать эти переменные static. Если убрать и static, и const, то GCC снова будет считать их константами, и мы получим тот же результат. Из-за таких static const переменных изменения в трёх функциях из тринадцати оказались ложными, но я не стал их исправлять.\r\n\r\nSQLite использует много глобальных переменных, и с этим связано большинство настоящих const-оптимизаций: вроде замены сравнения с переменной на сравнение с константой, или частичного отката цикла на один шаг (чтобы понять, какие были сделаны оптимизации, я воспользовался Radare). Несколько изменений не стоят упоминания. SQLite3ParseUri() содержит 487 инструкций, но const внёс лишь одно изменение: взял эти два сравнения:\r\n\r\ntest %al, %al\r\nje <SQLite3ParseUri+0x717>\r\ncmp $0x23, %al\r\nje <SQLite3ParseUri+0x717>\r\n\r\nИ поменял местами:\r\n\r\ncmp $0x23, %al\r\nje <SQLite3ParseUri+0x717>\r\ntest %al, %al\r\nje <SQLite3ParseUri+0x717>\r\n\r\nБенчмарки\r\n\r\nSQLite поставляется с регрессионным тестом для измерения производительности, и я сотни раз прогнал его для каждой версии кода, используя стандартные сборочные настройки SQLite. Длительность исполнения в секундах:\r\n\r\nconst\r\nБез const\r\nМинимум\r\n10,658\r\n10,803\r\nМедиана\r\n11,571\r\n11,519\r\nМаксимум\r\n11,832\r\n11,658\r\nСреднее\r\n11,531\r\n11,492\r\n\r\nЛично я не вижу особой разницы. Я убрал const изо всей программы, так что если бы была заметная разница, то её было был легко заметить. Впрочем, если для вас крайне важна производительность, то вас может порадовать даже крошечное ускорение. Давайте проведём статистический анализ.\r\n\r\nМне нравится использовать для таких задач тест Mann-Whitney U. Он аналогичен более известному тесту t, предназначенному для определения различий в группах, но более устойчив к сложным случайным вариациям, возникающим при измерении времени на компьютерах (из-за непредсказуемых переключений контекста, ошибок в страницах памяти и т.д.). Вот результат:\r\n\r\nconst	Без const\r\nN	100	100\r\nСредняя категория (Mean rank)	121,38	79,62\r\nMann-Whitney U		2912\r\nZ		-5,10\r\n2-sided p value		<10-6\r\nСредняя разница HL\r\n-0,056 с.\r\n95-процентный доверительный интервал\r\n-0,077… -0,038 с.\r\n\r\nТест U обнаружил статистически значимую разницу в производительности. Но — сюрприз! — быстрее оказалась версия без const, примерно на 60 мс, то есть на 0,5 %. Похоже, небольшое количество сделанных «оптимизаций» не стоили увеличения количества кода. Вряд ли const активировал какие-нибудь большие оптимизации, вроде автовекторизации. Конечно, ваш пробег может зависеть от различных флагов в компиляторе, или от его версии, или от кодовой базы, или от чего-нибудь ещё. Но мне кажется, будет честным сказать, что если даже const повысили производительность C, то я этого не заметил.\r\n\r\nТак для чего нужен const?\r\n\r\nПри всех его недостатках, const в C/C++ полезен для обеспечения типобезопасности. В частности, если применять const в сочетании с move-семантикой и std::unique_pointer, то можно реализовать явное владение указателем. Неопределённость владения указателем было огромной проблемой в старых кодовых базах на С++ размером свыше 100 KLOC, так что я благодарен const за её решение.\r\n\r\nОднако раньше я выходил за рамки использования const для обеспечения типобезопасности. Я слышал, что считалась правильным как можно активнее применять const ради повышения производительности. Я слышал, если производительность действительно важна, то нужно было рефакторить код, чтобы добавить побольше const, даже если код становился менее читабельным. В то время это звучало разумно, но с тех пор я понял, что это неправда.','2019-08-23 21:56:26',NULL,1),
(2,'Как Badoo добился возможности отдавать 200k фото в секунду','Современный веб практически немыслим без медиаконтента: смартфоны есть практически у каждой нашей бабушки, все сидят в соцсетях, и простои в обслуживании дорого обходятся компаниям. Вашему вниманию расшифровка рассказа компании Badoo о том, как она организовала отдачу фотографий с помощью аппаратного решения, с какими проблемами производительности столкнулась в процессе, чем они были вызваны, ну и как эти проблемы были решены с помощью софтового решения на основе Nginx, обеспечив при этом отказоустойчивость на всех уровнях (видео). Благодарим авторов рассказа Олега Sannis Ефимова и Александра Дымова, которые поделились своим опытом на конференции Uptime day 4.\r\n\r\n— Начнем с небольшого введения о том, как мы храним и кэшируем фотографии. У нас есть слой, на котором мы их храним, и слой, где мы фотографии кэшируем. При этом, если мы хотим добиваться большого хитрейта и снижать нагрузку на стораджи, нам важно, чтобы каждая фотография отдельного пользователя лежала на одном кэширующем сервере. Иначе нам пришлось бы ставить во столько раз больше дисков, во сколько у нас больше серверов. Хитрейт у нас в районе 99%, то есть мы в 100 раз снижаем нагрузку на наши storage, и для того, чтобы это сделать, еще 10 лет назад, когда все это строилось, у нас было 50 серверов. Соответственно, для того, чтобы эти фотографии отдавать, нам нужно было по сути 50 внешних доменов, которые эти серверы обслуживают. \r\n\r\nЕстественно, сразу встал вопрос: а если у нас один сервер упадет, будет недоступен, какую часть трафика мы теряем? Мы посмотрели, что есть на рынке, и решили купить железку, чтобы она решила все наши проблемы. Выбор пал на решение компании F5-network (которая, кстати, не так давно купила NGINX, Inc): BIG-IP Local Traffic Manager.\r\nЧто эта железка (LTM) делает: это железный роутер, который делает железное redundancy своих внешних портов и позволяет роутить трафик, основываясь на топологии сети, на каких-то настройках, делает health-check’и. Нам было важно то, что эту железку можно программировать. Соответственно, мы могли описать логику того, как фотографии определенного пользователя отдавались с какого-то конкретного кэша. Как это выглядит? Есть железка, которая смотрит в интернет по одному домену, одному ip, делает ssl offload, разбирает http-запросы, из IRule выбирает номер кэша, куда пойти, и пускает туда трафик. При этом она делает health-cheсk’и, и в случае недоступности какой-то машины мы сделали на тот момент так, чтобы трафик шел на один резервный сервер. С точки зрения конфигурирования есть, конечно, некоторые нюансы, но в целом все довольно просто: мы прописываем карту, соответствие какого-то числа нашему IP в сети, говорим, что слушать мы будем на 80-м и 443-м портах, говорим, что, если сервер недоступен, то нужно пускать трафик на резервный, в данном случае 35-й, и описываем кучу логики, как эту архитектуру надо разбирать. Единственная проблема была в том, что язык, которым программируется железка, это язык Tcl. Если кто вообще такой помнит… язык этот больше write-only, чем язык, удобный для программирования:\r\nЧто мы получили? Мы получили железку, которая обеспечивает высокую доступность нашей инфраструктуры, роутит весь наш трафик, обеспечивает health-cheсk’и и просто работает. Причем работает довольно долго: за последние 10 лет к ней не было никаких нареканий. К началу 2018 года мы уже отдавали около 80k фотографий в секунду. Это где-то примерно 80 гигабит трафика с обоих наших дата-центров.\r\n\r\nОднако…\r\n\r\nВ начале 2018 года мы на графиках увидели некрасивую картину: время отдачи фотографий явно выросло. И оно перестало нас устраивать. Проблема в том, что такое поведение было видно только в самый пик трафика — для нашей компании это ночь с воскресенья на понедельник. Но все остальное время система вела себя как обычно, никаких признаков поломки. \r\n\r\n\r\n\r\nТем не менее, проблему надо было решать. Мы определили возможные узкие места и начали их ликвидировать. В первую очередь, конечно, мы расширили uplinks внешние, провели полную ревизию внутренних uplinks, нашли все возможные узкие места. Но очевидного результата всё это не дало, проблема не исчезла.\r\n\r\nЕще одним возможным узким местом была производительность самих фото-кэшей. И мы решили, что, возможно, проблема упирается в них. Что ж, расширили производительность — в основном, сетевые порты на фотокэшах. Но снова никакого явного улучшения не видели. В конце концов, обратили пристальное внимание на производительность самого LTM-а, и вот тут увидели на графиках печальную картину: загрузка всех CPU начинает идти плавно, но потом резко упирается в полку. При этом LTM перестает адекватно реагировать на health-check\'и uplink\'ов и начинает их случайным образом выключать, что ведет к серьезной деградации производительности. \r\n\r\nТо есть мы определили источник проблемы, определили узкое место. Осталось решить, что же мы будем делать. \r\n\r\n\r\n\r\nПервое, само напрашивающееся, что мы могли предпринять, — это как-то модернизировать сам LTM. Но тут есть свои нюансы, потому что это железо достаточно уникальное, ты не пойдешь в ближайший супермаркет и не купишь. Это отдельный контракт, отдельный контракт на лицензию, и это займет немало времени. Второй вариант — начать думать самому, придумать свое решение на своих компонентах, желательно с использованием программы с открытым доступом. Осталось только решить, что именно мы выберем для этого и сколько времени потратим на решение этой проблемы, ведь пользователи недополучали фотографий. Стало быть, надо делать все это очень-очень быстро, можно сказать — вчера.\r\n\r\nТак как задача звучала как «сделать что-то максимально быстро и используя то железо, которое у нас есть», первое, что мы подумали, — это просто снять с фронта какие-нибудь не самые мощные машины, поставить туда Nginx, с которым мы умеем работать, и попробовать реализовать всю ту самую логику, которую раньше делала железка. То есть фактически мы оставляли нашу железку, ставили еще 4 сервера, которые должны были сконфигурировать, делали для них внешние домены по аналогии с тем, как это было 10 лет назад… Мы немного теряли в доступности в случае падения этих машин, но, тем не менее, решали локально проблему наших пользователей. \r\n\r\nСоответственно, логика остается той же самой: мы ставим Nginx, он умеет делать SSL-offload, мы можем на конфигах как-то спрограммировать логику роутинга, health-check\'и и просто продублировать ту логику, которая у нас была до этого. \r\n\r\nСадимся писать конфиги. Сначала казалось, что все было очень просто, но, к сожалению, под каждую задачу найти мануалы очень сложно. Поэтому не советуем просто гуглить «как сконфигурировать Nginx для фотографий»: лучше обратиться к официальной документации, которая покажет, какие настройки стоит трогать. Но конкретный параметр лучше подбирать самим. Ну, а дальше все просто: описываем серверы, которые у нас есть, описываем сертификаты… Но самое интересное — это, собственно, сама логика роутинга. \r\n\r\nПоначалу нам казалось, что мы просто описываем наш локейшн, матчим в нем номер нашего фотокэша, руками либо генератором описываем, сколько нам нужно апстримов, в каждом апстриме указываем сервер, на который должен идти трафик, и бэкапный сервер — в случае, если основной сервер недоступен:\r\n\r\n\r\n\r\nНо, наверное, если бы все было бы так просто, мы просто разошлись бы по домам и ничего не рассказывали. К сожалению, с дефолтными настройками Nginx, которые, в общем-то, сделаны за долгие годы разработки и не совсем под этот кейс… конфиг выглядит так: в случае, если у какого-то апстрим-сервера происходит ошибка запроса либо таймаут, Nginx всегда переключает трафик на следующий. При этом после первого фейла в течение 10 секунд сервер также будет выключен, причем и по ошибке, и по таймауту — это даже нельзя никак конфигурировать. То есть если мы уберем или сбросим в апстрим-директиве опцию таймаут, то, хотя Nginx и не будет обрабатывать этот запрос и ответит какой-нибудь не очень хорошей ошибкой, сервер будет выключаться. \r\n\r\n\r\n\r\nЧтобы этого избежать, мы сделали две вещи: \r\n\r\nа) запретили делать это Nginx\'у руками — и к сожалению, единственный способ сделать это — просто задать настройки max fails. \r\n\r\nб) вспомнили, что мы в других проектах используем модуль, который позволяет делать фоновые health-check\'и — соответственно, мы сделали довольно частые health-check\'и, чтобы простой в случае аварии у нас был минимальным. \r\n\r\nК сожалению, это тоже не все, потому что буквально первые две недели работы этой схемы показали, что TCP health-check — тоже штука ненадежная: на апстрим-сервере может быть поднят не Nginx, или Nginx в D-state, и в этом случае ядро будет принимать соединение, health-check будет проходить, а работать не будет. Поэтому мы сразу же заменили это на health-check http\'шный, сделали определенный, который если уж отдает 200, то все работает в этом скрипте. Можно делать дополнительную логику — например, в случае кэширующих серверов проверять, что правильно смонтирована файловая система:\r\n\r\n\r\n\r\nИ нас бы это устроило, за исключением того, что на данный момент схема полностью повторяла то, что делала железка. Но мы-то хотели сделать лучше. Раньше у нас был один резервный сервер, и, наверное, это не очень хорошо, потому что если серверов у вас сто, то когда падает сразу несколько, один резервный сервер вряд ли справится с нагрузкой. Поэтому мы решили резервирование распределить по всем серверам: сделали просто еще один отдельный апстрим, записали туда все сервера с определенными параметрами в соответствии с тем, какую нагрузку они могут обслуживать, добавили те же самые health-check\'и, которые у нас были до этого:\r\n\r\n\r\n\r\nТак как внутри одного апстрима нельзя ходить в другой апстрим, нужно было сделать так, чтобы в случае недоступности основного апстрима, в котором просто записывали правильный, нужный фотокэш, мы просто через error_page шли на fallback, откуда шли на резервный апрстрим:\r\n\r\n\r\n\r\nИ буквально добавив четыре сервера, мы вот что получили: заменили часть нагрузки — сняли с LTM на эти сервера, реализовали там ту же логику, используя стандартное железо и софт, сразу же получили бонусом, что эти сервера можно масштабировать, потому что их можно просто поставить столько, сколько нужно. Ну и единственный минус — мы потеряли высокую доступность для внешних пользователей. Но на тот момент пришлось этим пожертвовать, потому что надо было незамедлительно решить проблему. Итак, часть нагрузки мы сняли, это около 40% на тот момент, LTM\'у стало хорошо, а буквально через две недели после начала проблемы мы стали отдавать не 45k запросов в секунду, а 55k. По сути, мы выросли на 20% — это явно тот трафик, который мы недоотдавали пользователю. И после этого начали думать, как решить оставшуюся проблему — обеспечить высокую внешнюю доступность.\r\n\r\n\r\n\r\nУ нас была некоторая пауза, во время которой мы обсуждали, какое решение мы будем для этого использовать. Были предложения обеспечивать надежность с помощью DNS, с помощью каких-то самописных скриптов, протоколов динамической маршрутизации… вариантов было много, но уже стало ясно, что для по-настоящему надежной отдачи фотографий нужно ввести еще один слой, который будет за этим следить. Мы назвали эти машины photo directors. В качестве программного обеспечения, на которое мы опирались, был выбрал Keepalived:\r\n\r\n\r\n\r\nДля начала — из чего Keepalived состоит. Первое — это протокол VRRP, широко известный сетевикам, расположен на сетевом оборудовании, обеспечивающем отказоустойчивость внешнего IP-адреса, на который соединяются клиенты. Вторая часть это — IPVS, IP virtual server, для балансировки между фото-роутерами и обеспечения отказоустойчивости на этом уровне. И третье — health-check\'и.\r\n\r\nНачнем с первой части: VRRP — как это выглядит? Есть некий virtual IP, на который есть запись в dns badoocdn.com, куда подключаются клиенты. В какой-то момент времени у нас IP-адрес присутствует на каком-то одном сервере. Между серверами бегают по протоколу VRRP keepalived-пакеты, и в случае если мастер пропадает с радаров — сервер перезагрузился или еще что-нибудь, то бэкапный сервер автоматически поднимает этот IP адрес у себя — не надо делать никаких ручных действий. Отличаются мастер и бэкап, в основном priority: чем оно выше, тем больше шансов, что машина станет мастер. Очень большое достоинство, то что не надо конфигурировать IP-адреса на самом сервере, достаточно описать их в конфиге, и если при этом IP-адресам необходимы какие-то кастомные правила маршрутизации, это описывается прямо в конфиге, тем же синтаксисом, как это описывается в пакете VRRP. Никаких незнакомых вещей вам не встретится.\r\n\r\n\r\n\r\nКак это выглядит на практике? Что происходит, если один из серверов уходит в отказ? Как только мастер пропадает, у нас бэкап прекращает получать адвертисменты и автоматически становится мастером. Через какое-то время мы починили мастер, перезагрузили, подняли Keepalived — приходят адвертисменты с бОльшим приоритетом, чем у бэкапа, и бэкап автоматически превращается обратно, снимает с себя IP-адреса, никаких ручных действий при этом делать не надо. \r\n\r\n\r\n\r\nТаким образом, отказоустойчивость внешнего IP-адреса мы обеспечили. Следующая часть — это с внешнего IP-адреса как-то балансировать трафик на фото-роутеры, которые уже терминируют его. С протоколами балансировки все достаточно ясно. Это либо простой round-robin, либо немножко более сложные вещи, wrr, list connection и так далее. Это в принципе описано в документации, ничего такого особого нет. А вот метод доставки… Тут остановимся поподробнее — почему выбрали один из них. Это NAT, Direct Routing и TUN. Дело в том, что мы сразу закладывались на отдачу 100 гигабит трафика с площадок. Это если прикинуть, нужно 10 гигабитных карточек, правильно? 10 гигабитных карточек в одном сервере — это уже выходит за рамки, по крайней мере, нашего понятия «стандартное оборудование». И тут мы вспомнили, что мы не просто отдаем какой-то трафик, мы отдаем фотографии. \r\n\r\nВ чем особенность? — Колоссальная разница между входящим и исходящим трафиком. Входящий трафик очень маленький, исходящий очень большой:\r\n\r\n\r\n\r\nЕсли посмотреть на эти графики, то видно, что в данный момент на директора поступает порядка 200 Мб в секунду, это самый обычный день. Отдаем же мы обратно 4,500 Мб в секунду, соотношение у нас примерно 1/22. Уже понятно, что нам для полного обеспечения исходящего трафика на 22 сервера рабочих достаточно одного, который принимает это соединение. Тут нам на помощь приходит как раз алгоритм direct routing, алгоритм маршрутизации. \r\n\r\nКак это выглядит? Фото-директор у нас согласно своей таблице передает соединения на фото-роутеры. Но обратный трафик фото-роутеры отправляют уже напрямую в интернет, отправляют клиенту, он не проходит обратно через фото-директор, таким образом, минимальным количеством машин мы обеспечиваем полную отказоустойчивость и прокачку всего трафика. В конфигах это выглядит следующим образом: мы указываем алгоритм, в нашем случае это простой rr, обеспечиваем метод директ-роутинг и дальше начинаем перечислять все реальные сервера, сколько их у нас есть. Которые будут этот трафик детерминировать. В случае, если у нас там появляются еще один-два, несколько серверов, возникает такая необходимость — просто дописываем эту секцию в конфиге и особо не паримся. Со стороны реальных серверов, со стороны фото-роутера такой метод требует самого минимального конфигурирования, он прекрасно описан в документации, и подводных камней там нет. \r\n\r\nЧто особенно приятно — такое решение не подразумевает кардинальной переделки локальной сети, для нас это было важно, нам надо было решить это минимальными затратами. Если посмотреть на вывод команды IPVS admin, то мы увидим, как это выглядит. Вот у нас есть некий виртуальный сервер, на 443 порту, слушает, принимает соединение, идет перечисление всех рабочих серверов, и видно, что connection — он, плюс-минус, одинаковый. Если мы посмотрим статистику, на том же виртуальном сервере, — у нас есть входящие пакеты, входящие соединения, но абсолютно отсутствуют исходящие. Исходящие соединения идут напрямую клиенту. Хорошо, разбалансировать мы смогли. Теперь, что будет, если у нас один из фото-роутеров уходит в отказ? Ведь железо есть железо. Может уйти в kernel panic, может сломаться, может сгореть блок питания. Что угодно. Для этого и нужны health-check\'и. Они могут быть как самыми простыми — проверка на то, как порт у нас открыт, — так и какая-то более сложными, вплоть до каких-то самописных скриптов, которые будут даже бизнес-логику будут проверять.\r\n\r\nМы остановились где-то посередине: у нас идет https-запрос на определенный location, вызывается скрипт, если он отвечает 200-м ответом, мы считаем, что с этим сервером все нормально, что он живой и его совершенно спокойно можно включать. \r\n\r\nКак это, опять же, выглядит на практике. Выключили сервер допустим на обслуживание — перепрошивка BIOS, например. В логах у нас тут же происходит таймаут, видим первая строчка, потом после трех попыток помечается как «зафейлен», и он удаляется просто из списка. \r\n\r\n\r\n\r\nВозможен еще второй вариант поведения, когда просто VS выставляется в ноль, но в случае отдачи фотографии это работает плохо. Сервер поднимается, запускается там Nginx, тут же health-check\'и понимают, что коннект проходит, что все отлично, и сервер появляется у нас в списке, и на него тут же автоматически начинает подаваться нагрузка. Никаких при этом ручных действий от дежурного админа не требуется. Ночью сервер перезагрузился — отдел мониторинга нам по этому поводу ночью не звонит. В известность ставят, что такое было, все нормально. \r\n\r\nИтак, достаточно простым способ, с помощью небольшого количества сервером мы проблему внешней отказоустойчивости решили.\r\n\r\nОсталось сказать, что все это, конечно же, нужно мониторить. Отдельно нужно отметить, что Keepalivede, как очень давно написанный софт, имеет кучу способов его замониторить, как с помощью проверок через DBus, SMTP, SNMP, так и стандартным Zabbix\'ом. Плюс, он сам по себе умеет писать письма практически на каждый чих, и честно говоря, мы в какой-то момент думали даже выключить, потому что пишет он очень много писем на любое переключение трафика, включения, на каждый IP-шник и так далее. Конечно, если серверов много, то можно этими письмами себя завалить. Стандартными способами мониторим nginx на фото-роутерах, и никуда не делся мониторинг железа. Мы бы, конечно, советовали еще две вещи: это во-первых, внешние health-check\'и доступности, потому что даже если все работает, на самом деле, возможно, пользователи фотографии не получают из-за проблем с внешними провайдерами или чего-то более сложного. Всегда стоит держать где-нибудь в другой сети, в amazon или еще где-то, отдельную машину, которая сможет снаружи пинговать ваши сервера, и также стоит использовать либо anomaly detection, для тех, кто умеет в хитрый machine learning, либо простой мониторинг, хотя бы для того, чтобы отслеживать, если реквесты резко упали, либо наоборот, выросли. Тоже бывает полезно.\r\n\r\nПодведем итоги: мы, по сути, заменили железное решение, которое в какой-то момент перестало нас устраивать, довольно простой системой, которая делает все тоже самое, то есть обеспечивает терминирование HTTPS трафика и дальнейший умный роутинг с нужными health-check\'ами. Мы увеличили стабильность этой системы, то есть на каждый слой у нас все также высокая доступность, плюс мы бонусом получили то, что на каждом слое довольно просто все это масштабировать, потому что это стандартное железо со стандартным софтом, то есть тем самым мы упростили себе диагностику возможных проблем.\r\n\r\nЧто мы в итоге получили? Проблема у нас была в январские праздники 2018-го. За первые полгода пока мы вводили эту схему в строй, расширяли уже на весь трафик, чтобы весь трафик снять с LTM, мы выросли только по трафику в одном дата-центре с 40 гигабит до 60 гигабит, и при этом за весь 2018-й год смогли отдавать практически в три раза больше фотографий в секунду.','2019-08-23 21:58:36',NULL,1),
(3,'Инструменты для разработчиков приложений, запускаемых в Kubernetes','Современный подход к эксплуатации решает множество насущных проблем бизнеса. Контейнеры и оркестраторы позволяют легко масштабировать проекты любой сложности, упрощают релизы новых версий, делают их более надежными, но вместе с тем создают и дополнительные проблемы для разработчиков. Программиста, в первую очередь, заботит его код: архитектура, качество, производительность, элегантность, — а не то, как он поедет в Kubernetes и как его тестировать и отлаживать после внесения даже минимальных правок. Посему весьма закономерно и то, что активно развиваются инструменты для Kubernetes, помогающие решать проблемы даже самых «архаичных» разработчиков и позволяя им сосредоточиться на главном.\r\n\r\nВ этом обзоре представлена краткая информация о некоторых инструментах, которые упрощают жизнь программисту, чей код крутится в pod’ax Kubernetes-кластера.\r\n\r\nПростые помощники\r\n\r\nKubectl-debug\r\n\r\nСуть: добавь свой контейнер в Pod и посмотри, что в нем происходит.\r\nGitHub.\r\nКраткая статистика GH: 715 звёзд, 54 коммита, 9 контрибьюторов.\r\nЯзык: Go.\r\nЛицензия: Apache License 2.0.\r\n\r\nЭтот плагин для kubectl позволяет создать внутри интересующего pod\'a дополнительный контейнер, который будет делить пространство имен процессов с остальными контейнерами. В нем можно производить отладку работы pod\'а: проверить работу сети, послушать сетевой трафик, сделать strace интересующего процесса и т.п.\r\n\r\nТакже можно переключиться в контейнер процесса, выполнив chroot /proc/PID/root — это бывает очень удобно, когда нужно получить root shell в контейнере, для которого в манифесте выставлен securityContext.runAs.\r\n\r\nИнструмент прост и эффективен, так что может пригодиться каждому разработчику. Подробнее о нём мы писали в отдельной статье.\r\n\r\nTelepresence\r\n\r\nСуть: перенеси приложение на свой компьютер. Разрабатывай и отлаживай локально.\r\nСайт; GitHub.\r\nКраткая статистика GH: 2131 звезда, 2712 коммитов, 33 контрибьютора.\r\nЯзык: Python.\r\nЛицензия: Apache License 2.0.\r\n\r\nИдея этой оснастки заключается в запуске контейнера с приложением на локальном пользовательском компьютере и проксировании всего трафика из кластера в него и обратно. Такой подход позволяет вести разработку локально, просто изменяя файлы в своей любимой IDE: результаты будут доступны сразу же.\r\n\r\nПлюсы локального запуска — удобство правок и моментальный результат, возможность отлаживать приложение привычным способом. Из минусов — требовательность к скорости соединения, что особенно заметно, когда приходится работать с приложением с достаточно высоким RPS и трафиком. Кроме того, у Telepresence есть проблемы с volume mounts в Windows, что может стать решающим ограничителем для разработчиков, привыкшим к этой ОС.\r\n\r\nМы уже делились своим опытом использования Telepresence здесь.\r\n\r\nKsync\r\n\r\nСуть: почти мгновенная синхронизация кода с контейнером в кластере.\r\nGitHub.\r\nКраткая статистика GH: 555 звёзд, 362 коммита, 11 контрибьюторов.\r\nЯзык: Go.\r\nЛицензия: Apache License 2.0.\r\n\r\nУтилита позволяет синхронизировать содержимое локальной директории с каталогом контейнера, запущенного в кластере. Такой инструмент отлично подойдет для разработчиков на скриптовых языках программирования, основная проблема у которых — доставить код в работающий контейнер. Ksync призван снять эту головную боль.\r\n\r\nПри однократной инициализации командой ksync init в кластере создается DaemonSet, который используется для отслеживания состояния файловой системы выбранного контейнера. На своем локальном компьютере разработчик запускает команду ksync watch, которая следит за конфигурациями и запускает syncthing, осуществляющую непосредственную синхронизацию файлов с кластером.\r\n\r\nОстается проинструктировать ksync, что и с чем синхронизировать. Например, такая команда:\r\n\r\nksync create --name=myproject --namespace=test --selector=app=backend --container=php --reload=false /home/user/myproject/ /var/www/myproject/\r\n\r\n… создаст watcher с именем myproject, который будет искать pod с меткой app=backend и пытаться синхронизировать локальную директорию /home/user/myproject/ с каталогом /var/www/myproject/ у контейнера под названием php.\r\n\r\nПроблемы и примечания по ksync из нашего опыта:\r\n\r\nНа узлах Kubernetes-кластера должна использоваться overlay2 в качестве storage driver для Docker. Ни с какими другими утилита работать не будет.\r\nПри использовании Windows в качестве ОС клиента возможна некорректная работа watcher\'а файловой системы. Данный баг замечен при работе с крупными каталогами — с большим количеством вложенных файлов и директорий. Мы создали соответствующий issue в проекте syncthing, но прогресса по нему пока (с начала июля) нет.\r\nИспользуйте файл .stignore для того, чтобы указать пути или шаблоны файлов, которые не нужно синхронизировать (например, каталоги app/cache и .git).\r\nПо умолчанию ksync будет перезагружать контейнер при каждом изменении файлов. Для Node.js это удобно, а для PHP — совершенно излишне. Лучше выключить opcache и использовать флаг --reload=false.\r\nКонфигурацию можно всегда исправить в $HOME/.ksync/ksync.yaml.\r\n\r\nSquash\r\n\r\nСуть: отлаживай процессы прямо в кластере.\r\nGitHub.\r\nКраткая статистика GH: 1154 звёзд, 279 коммитов, 23 контрибьютора.\r\nЯзык: Go.\r\nЛицензия: Apache License 2.0.\r\n\r\nДанный инструмент предназначен для отладки процессов непосредственно в pod\'ах. Утилита проста и в интерактивном режиме позволяет выбрать нужный отладчик (см. ниже) и namespace + pod, в процесс которого нужно вмешаться. В настоящее время поддерживаются:\r\n\r\ndelve — для приложений на Go;\r\nGDB — через target remote + проброс порта;\r\nпроброс порта JDWP для отладки Java-приложений.\r\n\r\nСо стороны IDE поддержка есть лишь в VScode (с помощью расширения), однако в планах на текущий (2019) год значатся Eclipse и Intellij.\r\n\r\nДля отладки процессов Squash запускает на узлах кластера привилегированный контейнер, поэтому необходимо сперва ознакомиться с возможностями безопасного режима во избежание проблем с безопасностью.\r\n\r\nКомплексные решения\r\n\r\nПереходим к тяжелой артиллерии — более «масштабным» проектам, призванным сразу закрыть многие потребности разработчиков.\r\n\r\nNB: В этом списке, безусловно, есть место и нашей Open Source-утилите werf (ранее известной как dapp). Однако мы уже не раз писали и рассказывали о ней, а посему решили не включать в обзор. Для желающих ознакомиться с её возможностями поближе рекомендуем прочитать/послушать доклад «werf — наш инструмент для CI/CD в Kubernetes».\r\n\r\nDevSpace\r\n\r\nСуть: для тех, кто хочет начать работать в Kubernetes, но не хочет глубоко залезать в его дебри.\r\nGitHub.\r\nКраткая статистика GH: 630 звёзд, 1912 коммитов, 13 контрибьюторов.\r\nЯзык: Go.\r\nЛицензия: Apache License 2.0.\r\n\r\nРешение от одноименной компании, предоставляющей managed-кластеры с Kubernetes для командной разработки. Утилита была создана для коммерческих кластеров, однако отлично работает и с любыми другими.\r\n\r\nПри запуске команды devspace init в каталоге с проектом вам предложат (в интерактивном режиме):\r\n\r\nвыбрать рабочий Kubernetes-кластер,\r\nиспользовать имеющийся Dockerfile (или сгенерировать новый) для создания контейнера на его базе,\r\nвыбрать репозиторий для хранения образов контейнеров и т.д.\r\n\r\nПосле всех этих подготовительных действий можно начинать разработку, выполнив команду devspace dev. Она соберёт контейнер, загрузит его в репозиторий, выкатит deployment в кластер и запустит проброс портов и синхронизацию контейнера с локальным каталогом.\r\n\r\nОпционально будет предложено перейти терминалом в контейнер. Отказываться не стоит, потому как в реальности контейнер стартует с командой sleep, а для реального тестирования приложение требуется запускать вручную.\r\n\r\nНаконец, команда devspace deploy выкатывает приложение и связанную с ним инфраструктуру в кластер, после чего все начинает функционировать в боевом режиме.\r\n\r\nВся конфигурация проекта хранится в файле devspace.yaml. Помимо настроек окружения для разработки в нем же можно найти описание инфраструктуры, похожее на стандартные манифесты Kubernetes, только сильно упрощенные.\r\n\r\n\r\nАрхитектура и основные этапы работы с DevSpace\r\n\r\nКроме того, в проект легко добавить предопределенный компонент (например, СУБД MySQL) или Helm-чарт. Подробнее читайте в документации — она несложная.\r\n\r\nSkaffold\r\n\r\nСайт; GitHub.\r\nКраткая статистика GH: 7423 звезды, 4173 коммита, 136 контрибьюторов.\r\nЯзык: Go.\r\nЛицензия: Apache License 2.0.\r\n\r\nЭта утилита от Google претендует на то, чтобы покрыть все потребности разработчика, чей код так или иначе будет запускаться в кластере Kubernetes. Начать пользоваться им не так просто, как devspace\'ом: никакой интерактивности, определения языка и автосоздания Dockerfile здесь вам не предложат.\r\n\r\nВпрочем, если это не пугает — вот что позволяет делать Skaffold:\r\n\r\nОтслеживать изменения исходного кода.\r\nСинхронизировать его с контейнером pod\'а, если он не требует сборки.\r\nСобирать контейнеры с кодом, если ЯП — интерпретируемый, или же компилировать артефакты и упаковывать их в контейнеры.\r\nПолучившиеся образы автоматически проверять с помощью container-structure-test.\r\nТегировать и загружать образы в Docker Registry.\r\nРазворачивать приложение в кластере, используя kubectl, Helm или kustomize.\r\nДелать проброс портов.\r\nОтлаживать приложения, написанные на Java, Node.js, Python.\r\n\r\nWorkflow в различных вариациях декларативно описывается в файле skaffold.yaml. Для проекта можно также определить несколько профилей, в которых частично или полностью изменять стадии сборки и деплоя. Например, для разработки указать удобный для разработчика базовый образ, а для staging и production — минимальный (+ использовать securityContext у контейнеров или же переопределить кластер, в котором приложение будет развернуто).\r\n\r\nСборка Docker-контейнеров может осуществляться локально или удаленно: в Google Cloud Build или в кластере с помощью Kaniko. Также поддерживаются Bazel и Jib Maven/Gradle. Для тегирования Skaffold поддерживает множество стратегий: по git commit hash, дате/времени, sha256-сумме исходников и т.п.\r\n\r\nОтдельно стоит отметить возможность тестирования контейнеров. Уже упомянутый фреймворк container-structure-test предлагает следующие методы проверки:\r\n\r\nВыполнение команд в контексте контейнера с отслеживанием exit-статусов и проверкой текстового «выхлопа» команды.\r\nПроверка наличия файлов в контейнере и соответствия атрибутов указанным.\r\nКонтроль содержимого файлов по регулярным выражениям.\r\nСверка метаданных образа (ENV, ENTRYPOINT, VOLUMES и т.п.).\r\nПроверка совместимости лицензий.\r\n\r\nСинхронизация файлов с контейнером осуществляется не самым оптимальным способом: Skaffold просто создает архив с исходниками, копирует его и распаковывает в контейнере (должен быть установлен tar). Поэтому, если ваша основная задача — в синхронизации кода, лучше посмотреть в сторону специализированного решения (ksync).\r\n\r\n\r\nОсновные этапы работы Skaffold\r\n\r\nВ целом же инструмент не позволяет абстрагироваться от Kubernetes-манифестов и не имеет какой-либо интерактивности, поэтому может показаться сложным для освоения. Но в этом же и его плюс — большая свобода действий.\r\n\r\nGarden\r\n\r\nСайт; GitHub.\r\nКраткая статистика GH: 1063 звезды, 1927 коммитов, 17 контрибьюторов.\r\nЯзык: TypeScript (планируется разбить проект на несколько компонентов, некоторые из которых будут на Go, а также сделать SDK для создания дополнений на TypeScript/JavaScript и Go).\r\nЛицензия: Apache License 2.0.\r\n\r\nКак и Skaffold, Garden нацелен на автоматизацию процессов доставки кода приложения в K8s-кластер. Для этого сперва необходимо описать структуру проекта в YAML-файле, после чего запустить команду garden dev. Она сделает всю магию:\r\n\r\nСоберет контейнеры с различными частями проекта.\r\nПроведет интеграционные и unit-тесты, если таковые были описаны.\r\nВыкатит все компоненты проекта в кластер.\r\nВ случае изменения исходного кода — заново запустит весь пайплайн.\r\n\r\nОсновной упор при использовании этого инструмента делается на совместное использование удаленного кластера командой разработчиков. В этом случае, если какие-то стадии сборки и тестирования уже были сделаны, это значительно ускорит весь процесс, поскольку Garden сможет использовать закэшированные результаты.\r\n\r\nМодулем проекта может быть контейнер, Maven-контейнер, Helm-чарт, манифест для kubectl apply или даже OpenFaaS-функция. Причем любой из модулей можно подтянуть из удаленного Git-репозитория. Модуль может определять (а может и нет) сервисы, задачи и тесты. Сервисы и задачи могут иметь зависимости, благодаря чему можно определить последовательность деплоя того или иного сервиса, упорядочить запуск заданий и тестов.\r\n\r\nGarden предоставляет пользователю красивый dashboard (пока в экспериментальном состоянии), в котором отображается граф проекта: компоненты, последовательность сборки, выполнения задач и тестов, их связи и зависимости. Прямо в браузере можно просмотреть и логи всех компонентов проекта, проверить, что выдает тот или иной компонент по HTTP (если, конечно, для него объявлен ресурс ingress).\r\n\r\n\r\nПанель для Garden\r\n\r\nЕсть у этого инструмента и режим hot-reload, который просто синхронизирует изменения скриптов с контейнером в кластере, многократно ускоряя процесс отладки приложения. У Garden хорошая документация и неплохой набор примеров, позволяющих быстро освоиться и начать пользоваться. Кстати, совсем недавно мы публиковали перевод статьи от его авторов.\r\n\r\nЗаключение\r\n\r\nРазумеется, данным списком инструментарий для разработки и отладки приложений в Kubernetes не ограничивается. Существует еще много весьма полезных и практичных утилит, достойных если не отдельной статьи, то — как минимум — упоминания. Расскажите, чем пользуетесь вы, с какими проблемами вам доводилось сталкиваться и как вы их решали!','2019-08-23 22:01:09',NULL,1),
(4,'Вахтёры фриланса','Люди, проектировавшие настройки специализаций для фрилансеров на других ресурсах, явно имеют какое-то своё представление о реальности, в которой каждый фрилансер — это робот, с пелёнок запрограммированный на выполнение конкретного типа работ в строго определённом круге задач по принципу «Умеешь считать? Будешь бухгалтером». И эти люди не шутят в своём стремлении навязать свои представления самой реальности. Простой пример: на fl.ru больше двухсот специализаций, разбитых на 20 категорий — из них фрилансеру бесплатно доступна одна (!), а при покупке Pro-аккаунта, который стоит от полутора тысяч рублей в месяц — целых пять. \r\nПять из более, чем двухсот специализаций. Приобретение аккаунта Pro по некоторым из которых стоит более двух с половиной тысяч рублей в месяц. За пять специализаций из двухсот.\r\n\r\nТакое ощущение, что разработчики fl.ru людей, которые в состоянии делать больше пяти вещей, в своей жизни никогда не встречали. Проходят годы, домены становятся короче, а фриланс.ру остаётся фрилансом.ру.\r\n\r\nНа kwork.ru нет как таковой специализации профиля пользователя, но есть биржа проектов, рассортированных по 69 рубрикам, из которых фрилансер может выбрать любые семь. \r\nПочему именно семь? Почему не шесть? Почему не восемь? Почему не шестьдесят восемь? Откуда и зачем это ограничение в семь рубрик, которые фрилансер может выбрать, кастомизируя ленту проектов под свои нужды? Возможно, в «Кворке» работают крайне суеверные люди, которые верят, что число семь приносит удачу? И это ещё самое логичное из всех возможных объяснений, которые пришли мне на ум.\r\n\r\nРазумеется, вопросы это риторические и ответ на них мне прекрасно известен — просто он не из области юзабилити, а из области психологии: синдром вахтёра. \r\n\r\nОн особенно часто и ярко проявляется у компаний, бизнес-модель которых построена на freemium-модели с ограниченным набором бесплатных услуг и полным функционалом, спрятанным за paywall — просто иногда такие сервисы, даже взяв с пользователя деньги за доступ, про вторую половину сделки — полноту функционала — почему-то забывают.\r\n\r\nЭто потрясающе, как глубоко в людях может засесть синдром «держать и не пущать», если и ослабляя хватку, то по чуть-чуть и за деньги, что даже в такой, как принято считать, прогрессивной области, как интернет-индустрия, его проявления могут оставаться незамеченными на самом виду столь долгое время.\r\n\r\nВпрочем, проблемы с кастомизацией встречаются не только в виде ограниченного, но и навязанного выбора, как в случае с workspace.ru, который позволяет как настроить специализации в профиле фрилансера, как на fl.ru, так и кастомизировать ленту проектов, как на kwork.ru — но, в отличие от них обоих, без каких-либо ограничений выбора из десятков доступных вариантов. So far so good. \r\n\r\nПо отдельности возможность как выбрать неограниченное число специализаций, так и указать примерную стоимость своей работы в почасовом или попроектном выражении — это замечательные возможности. \r\n\r\nНо если их совместить, то шведский стол оборачивается мышеловкой: у каждой выбранной специализации фрилансеру нужно указать ориентировочный бюджет проекта и/или стоимость часа своей работы индивидуально, что удваивает и даже утраивает общее количество требуемых от пользователей действий, добавляя к выбору нужных чекбоксов заполнение сопуствующих полей.\r\n\r\n','2019-08-23 22:02:14',NULL,1),
(5,'21 сентября Badoo PHP Meetup #3: производительность','В этот раз в качестве общей темы встречи выбрали производительность PHP-кода и PHP-бэкенда в целом. Для нас эта область важна, так как, с одной стороны, у нас большая инфраструктура на PHP, и вопрос производительности — это вопрос экономии денег.  С другой — нам важно предоставлять пользователям сервис высокого качества, поэтому бэкенд должен отвечать достаточно быстро, ведь от этого зависит активность пользователей и их впечатления от сервиса.\r\n\r\nНа митапе хотим обсудить, как решают подобные вопросы в разных компаниях, а именно: как следить за производительностью, профилировать и локализовывать проблемы, когда и что стоит оптимизировать и как это делать.\r\n\r\nРегистрация по ссылке, начало в 12:00, гостей встречаем с 11:00. \r\n\r\nПрограмма\r\n\r\nПавел Мурзаков, PHP Team Lead (Badoo)\r\n\r\n«Боремся с shared-nothing моделью: PHP 7.4 preload, RoadRunner и другие»\r\n\r\nТрадиционное PHP-приложение (т.е. mod_php, php-fpm и т. п.) каждый раз исполняет весь код с нуля. Это значит, что весь bootstrap приложения происходит заново на каждый запрос: инициализация окружения, подключение необходимых файлов, сборка DI-контейнеров, загрузка конфигов и прочее. Всё это одинаково для каждого запроса, и могло быть сделано один раз, но PHP приходится постоянно повторять эти действия. Поэтому, даже если бизнес-логика достаточно оптимизирована, мы всё равно будем тратить ресурсы впустую на инициализацию. \r\n\r\nВ докладе поговорим, как можно решить или минимизировать эту проблему:\r\n\r\nРазберёмся, на что именно тратятся ресурсы, посмотрим в perf и исходники PHP.\r\nПоищем какие-то простые решения проблемы: как мы можем делать меньше инициализаций или сохранить данные между запросами. \r\nОпробуем новые достижения PHP-сообщества — PHP 7.4 preload и RoadRunner — и сравним их. \r\nРазберёмся, зачем нужен PHP 7.4 preload, если уже есть opcache, и как выжать из RoadRunner ещё больше.\r\n\r\nАнтон Шабовта zloyusr, энтузиаст асинхронного PHP (Onliner)\r\n\r\n«Когда производительности PHP-кода не хватает: пишем С драйвер для PHP + RoadRunner»\r\n\r\nОсновные тезисы:\r\n\r\nRoadRunner: протокол и особенности реализации\r\nPHP + Go — это быстро, надо ли еще оптимизировать?\r\nРеализация клиентского кода на С: с чего начать и когда вообще стоит переносить что-то в PHP-extension?\r\nСравнение производительности PHP-FPM, RoadRunner и RoadRunner + C.\r\nБонус: а если асинхронно? :)\r\n\r\nМесто спикера свободно!\r\n\r\nЕсли вам есть что рассказать о производительности PHP-бэкенда — пишите мне на Хабрапочту pmurzakov \r\n\r\n\r\n\r\nАдрес: Москва, Цветной бульвар, д.2, подъезд А, Cafetera (1 этаж)\r\nНачало докладов в 12:00.\r\n \r\nВстречать гостей начнем в 11:00, приходите выпить кофе перед началом и занять места получше!\r\n \r\nВ перерывах можно будет посмотреть офис Badoo, после митапа — афтепати для желающих. \r\n\r\nПожалуйста, при регистрации указывайте свои имена и фамилии, как в паспорте (на русском языке). Для пропуска в БЦ захватите с собой документ, удостоверяющий личность. \r\n \r\nКоличество мест ограничено, обязательно дождитесь подтверждения регистрации (придет за пару недель до митапа). \r\n\r\nТрансляция будет на нашем YouTube-канале, анонсы будут в группах VK и FB. Записи опубликуем там же и в блоге на Habr.\r\n\r\nПрисоединяйтесь к чату митапа, там регулярно бывают интересные обсуждения!','2019-08-23 22:03:05',NULL,1),
(6,'Зубная фея тут не работает: структура эмали зубов крокодилов и их доисторических предков','Вы заходите в коридор с приглушенным светом, в нем вам встречаются обездоленные души, терзаемые болью и страданиями. Но им не будет тут покоя, ибо за каждой из дверей их ждет еще больше мук и страха, наполняющие все клеточки тела и заполоняющие все мысли. Вы подходите к одной из дверей, за которой слышится адский скрежет и жужжание, пробирающие до костей. Собрав остатки смелости в кулак, вы протягиваете холодную от ужаса руку к ручке двери, как вдруг кто-то сзади касается вашего плеча, и вы, вздрогнув от неожиданности, оборачиваетесь. «Доктор освободится через несколько минут. Присядьте пока, мы вас позовем», — сообщает вам нежный голос медсестры. Видимо именно так себе представляют поход к стоматологу некоторые люди, которые к этим «садистам» в белых халатах относятся крайне отрицательно. Но мы сегодня не будем говорить о дентофобии, мы будем говорить о крокодилах. Да-да, именно о них, а точнее об их зубках, которые в стоматологическом лечении не нуждаются. \r\n\r\nУченые из университета Миссури (США) провели исследование зубов крокодилов, которое показало занятные особенности эмали этих безупречных охотников, полагающихся как раз на свои челюсти. Что выяснили ученые, чем отличаются зубы современных крокодилов от их доисторических родственников и какая от этого исследования польза? Об этом мы узнаем из доклада исследовательской группы.\r\n\r\nОснова исследования\r\n\r\nДля большинства позвоночных зубы являются неотъемлемым атрибутом получения и употребления пищи (муравьеды не в счет). Некоторые из хищников полагаются во время охоты на скорость (гепарды), некоторые — на коллектив (львы), а для некоторых огромную роль играет сила их укуса. Это относится и к крокодилам, которые подкрадываются к своим жертвам в воде и хватают их своими мощными челюстями. Чтобы жертва не смогла вырваться, захват должен быть мощный, а это выливается в большие нагрузки на костную структуру. Чтобы нивелировать отрицательный эффект своих мощных укусов у крокодилов имеется вторичное костное нёбо, которое неподвижно соединено с черепом. \r\n\r\n\r\nНаглядная демонстрация закрытия и открытия челюсти крокодила.\r\n\r\nОдной из основных особенностью крокодильих зубов является их постоянная замена на новые, когда старые изнашиваются. Дело в том, что зубы крокодилов напоминают матрешку, внутри которой развиваются новые зубы. Примерно раз в 2 года каждый из зубов в челюсти меняется на новые.\r\n\r\n\r\nОбратите внимание, насколько плотно замыкается этот «зубной капкан».\r\n\r\nЗубы крокодилов разделяются на несколько категорий по форме и соответствующему функционалу. В начале челюсти есть по 4 больших клыка, которые нужны для эффективного захвата добычи. В середине расположены более толстые зубки, которые увеличиваются вдоль челюсти. Эта часть нужна для разрезания добычи. У основания зубы расширяются и становятся более плоскими, что позволяет крокодилам раскусывать раковины моллюсков и панцири черепах, как семечки. \r\n\r\nНасколько же сильна челюсть крокодила? Естественно, это зависит от его размеров и вида. К примеру, в 2003 году выяснили, что 272-килограммовый миссисипский аллигатор кусает с силой ～9500 Н (Н — Ньютон, 1 Н = 1 кг·м/с2). А вот 1308-килограммовый гребнистый крокодил продемонстрировал умопомрачительные ～34500 Н. К слову, абсолютная сила укуса у человека составляет примерно 1498 Н.\r\n\r\nСила укуса зависит не столько от зубов, сколько от челюстных мышц. У крокодилов эти мышцы очень плотные и их много. Однако существует сильная разница между очень развитыми мышцами, отвечающими за закрытие пасти (что и дает такую силу укуса), и слабыми мышцами, отвечающими за открытие пасти. Это объясняет почему закрытую пасть крокодила можно удержать с помощью простого скотча.\r\n\r\n\r\nА ну-ка, покажи, кто тебя малявкой назвал.\r\n\r\nНо челюсть крокодилам нужна не только для безжалостных убийств ради пропитания, но и для заботы о своем потомстве. Самки крокодилов часто переносят своих детенышей именно в челюсти (сложно найти более безопасное для них место, ибо кто вздумает туда лезть). Пасть крокодилов оснащена очень чувствительными рецепторами, благодаря которым они могут регулировать силу прикуса, что позволяет им лучше удерживать добычу или аккуратненько переносить деток.\r\n\r\nЗубы человека, к сожалению, не отрастают после выпадения старых, но имеется нечто общее с крокодилами — эмаль.\r\n\r\n\r\nИзображение №1: каудальный зуб миссисипского аллигатора (Alligator mississippiensis).\r\n\r\nЭмаль это внешняя оболочка коронковой части зуба. Это самая прочная часть тела человека, как и многих других позвоночных. Однако у нас, как мы знаем, зубы не меняются на новые, потому наша эмаль должна быть толще. А вот у крокодилов изношенные зубы меняются на новые, потому в толстой эмали нет необходимости. Звучит вполне логично, то так ли все на самом деле?\r\n\r\nУченые говорят, что понимание изменений эмали внутри одного таксона позволят в дальнейшем лучше помнить как изменяется структура эмали в зависимости от биомеханики и диеты животного. \r\n\r\nКрокодилы, а именно Alligator mississippiensis, отлично подходят для этого исследования по ряду причин. Во-первых, их зубы, сила укуса и структура эмали меняются в зависимости от возраста и размеров особи, что обусловлено еще и сменой диеты. Во-вторых, зубы крокодилов имеют разную морфологию в зависимости от положения в челюсти. \r\n\r\n\r\nИзображение №2: а и b показывают разницу зубов между крупными и мелкими особями, с-е показывают зубы ископаемых предков современных крокодилов.\r\n\r\nРостральные зубы тонкие и используются для захвата добычи, в то время как каудальные зубы тупые и используются для дробления с более высокими силами укуса. Другими словами нагрузка на зуб зависит от его положения в челюсти и от размеров владельца этой челюсти.\r\n\r\nВ данном исследовании представлены результаты анализа и измерений абсолютной толщины эмали (AET) и стандартизированной по размеру (относительной) толщины эмали (RET) зубов крокодила.\r\n\r\nAET представляет собой оценку среднего расстояния от эмали-дентинового перехода до внешней поверхности эмали и представляет собой линейное измерение. А RET — это безразмерная величина, которая позволяет сравнивать относительную толщину эмали в разных масштабах.\r\n\r\nУченые провели оценку AET и RET рострального (в «носу» челюсти), промежуточного (в середине ряда) и каудального (у основания челюсти) зубов у семи особей вида Alligator mississippiensis.\r\n\r\nВажно также отметить, что структура эмали может зависеть от диеты особи и всего вида в целом. У крокодилов диета весьма обширная (что поймали, то и будет обедом), но она отличается от той, что была у их родственников, которые уже давно вымерли. Чтобы проверить это с точки зрения эмали, ученые провели анализ AET и RET ископаемых Protosuchidae (UCMP 97638), Iharkutosuchus (MTM VER 2018.837) и Allognathosuchus (YPM-PU 16989). Protosuchidae является представителем юрского периода, Iharkutosuchus — мелового периода, а Allognathosuchus из эоцена.\r\n\r\nПеред началом фактических измерений исследователи провели мозговой штурм и предложили несколько теоретических гипотез:\r\n\r\nгипотеза 1а — поскольку AET является линейной мерой и должна зависеть от размера, предполагается, что дисперсия в AET будет лучше всего объясняться размером черепа;\r\nгипотеза 1b — поскольку RET стандартизирован по размеру, предполагается, что дисперсия в RET будет лучше всего объяснена положением зуба;\r\nгипотеза 2а — поскольку AET и длина черепа являются линейными мерами размера, они должны масштабироваться с изометрическим наклоном;\r\nгипотеза 2b — поскольку каудальные зубы испытывают наибольшие силы прикуса в зубном ряду, следовательно RET будет выше у каудальных зубов.\r\n\r\n\r\nВ таблицах ниже представлены данные образцов (черепа крокодилов вида Alligator mississippiensis, взятые из заповедника Рокфеллера в Гранд Шенье, Луизиана, и ископаемых).\r\n\r\n\r\nТаблица №1: данные сканирования зубов крокодилов (ростральные, промежуточные и каудальные).\r\n\r\n\r\nТаблица №2: данные зубов (LSkull — длина черепа, hCrown — высота коронки, VE — объем эмали, VD — объем дентина, SAEDJ — площадь интерфейса эмаль-дентин, AET — абсолютная толщина эмали, RET — относительная толщина эмали).\r\n\r\nРезультаты исследования\r\n\r\nВ соответствии с дентальными данными, представленными в таблице №2, ученые пришли к выводу, что толщина эмали масштабируется изометрически с длиной черепа независимо от положения зуба.\r\n\r\n\r\nТаблица №3: значения AET и RET в зависимости от переменных.\r\n\r\n\r\nИзображение №3: масштабирование AET/RET по отношению к длине черепа.\r\n\r\nВ то же время, толщина эмали на каудальных зубах значительно больше, чем на других, но это также не зависит от длины черепа.\r\n\r\n\r\nТаблица №4: средние значения толщины эмали у высших позвоночных (Crocodyliform — внетаксоновая группа крокодилов, Dinosaur — динозавры, Artiodactyl — парнокопытные, Odontocete — подотряд китообразных, Perissodactyl — непарнокопытные, Primate — приматы, Rodent — грызуны).\r\n\r\n\r\nИзображение №4: толщина эмали каудальных зубов больше, чем других.\r\n\r\nДанные касательно масштабирования (таб. №3) подтвердили гипотезу 1а, поясняющая зависимость значения AET от длины черепа, а не от положения зуба. А вот значения RET, наоборот, зависят от положения зуба в ряду, а не от длины черепа, что подтверждает гипотезу 1b.\r\n\r\nОстальные гипотезы (2а и 2b) также были подтверждены, что следует из данных анализа средней толщины эмали зубов с разным расположением в ряду.\r\n\r\nСравнение толщины эмали у современного миссисипского аллигатора и его древних прародителей показало много общего, но были и отличия. Так, у Allognathosuchus толщина эмали примерно на 33% больше, чем у современных крокодилов (изображение ниже).\r\n\r\n\r\nИзображение №5: сравнение средней толщины эмали у аллигатора и ископаемых крокодиловых по высоте зубной коронки.\r\n\r\nСуммируя все вышеперечисленные данные, ученые пришли к выводу, что толщина эмали напрямую зависит от, так сказать, роли зубов. Если эти зубы необходимы для дробления, то их эмаль будет значительно толще. Ранее было установлено, что давление (сила сжатия) каудальных зубов выше, чем ростральных. Это связано именно с их ролью — удерживать добычу и дробить кости. Таким образом, более толстая эмаль предотвращает повреждение зубов, которые во время питания подвергаются максимальной нагрузке. И действительно, данные говорят о том, что каудальные зубы у крокодилов ломаются значительно реже, несмотря на серьезные нагрузки.\r\n\r\nКроме того, было обнаружено, что у зубов Allognathosuchus эмаль значительно толще, чем у остальных исследованных крокодиловых. Считается, что этот ископаемый вид предпочитал питаться черепахами, а для дробления их панцирей нужны прочные зубки и толстая эмаль. \r\n\r\nУченые также провели сравнение толщины эмали крокодиловых и некоторых динозавров, соответствующего предположительного веса и размера. Этот анализ показал, что у крокодиловых эмаль была толще (диаграмма ниже).\r\n\r\n\r\nИзображение №6: сравнение толщины эмали крокодиловых и динозавров.\r\n\r\nЛюбопытно, что эмаль у тираннозаврида была практически такой же толщины, что и у значительно меньшего по размерам Allognathosuchus и даже современных крокодилов. Логично, что структура зуба крокодилов объясняется их повадками в аспектах охоты и диеты.\r\n\r\nОднако, несмотря на свои рекорды, эмаль у архозавров (крокодилы, динозавры, птерозавры и т.д.) тоньше, чем у млекопитающих.\r\n\r\n\r\nИзображение №7: сравнение толщины эмали (AET) крокодилов и некоторых видов млекопитающих.\r\n\r\nПочему же эмаль охотников, так сильно полагающихся на свои челюсти, тоньше, чем у млекопитающих? Ответ на этот вопрос был еще в начале — замена изношенных зубов на новые. Хоть у крокодилов и прочные зубки, но им не нужны, так сказать, сверхпрочные, ввиду того, что новый зуб всегда придет на замену сломанному. У млекопитающих (по большей степени) такого таланта нет.','2019-08-23 22:04:29',NULL,1),
(7,'Информационная безопасность — что нужно знать и уметь, чтобы считаться хорошим специалистом по ИБ?','Действительно, эксперты в сфере кибербезопасности защищают деньги, данные, репутацию компаний, их сотрудников и пользователей. Гордиться есть чем. Тем не менее, о тех, кто защищает нашу с вами безопасность в интернет-пространстве, известно далеко не так много, как о разработчиках, о которых говорят и пишут. Кто-то написал приложение или игру, которые принесли создателю популярность и деньги, еще кто-то разработал криптовалютную платформу, на которую обратили внимание криптобиржи. Работа «инфобезопасников» остается скрытой от любопытных глаз. \r\n \r\nТем не менее, она важна не менее, чем дело рук программистов, ведь их продукты в какой-то мере становятся популярными и благодаря слаженной работе экспертов по кибербезопасности. О том, что представляет собой сама профессия и на что можно рассчитывать, когда начинаешь свой путь в качестве ИБ, и рассказывает эта статья. Разобраться в этой сложной теме помог Виктор Чаплыгин преподаватель факультета GeekBrains по информационной безопасности (ИБ).\r\n\r\n\r\nКто может назвать себя специалистом по ИБ?\r\n\r\nКак и во многих других технических специальностях, в инфобезе специалист — тот, кто обладает значительным техническим бэкграундом. У такого человека должен быть солидный опыт практической работы с разными технологиями (какими именно — поговорим ниже), но должна быть на высоте и теоретическая подготовка. Плюс ко всему, и это то, чего нет в большинстве других специальностей — он должен неплохо разбираться и в комплаенсе, т.е. знать законодательные нормы и требования области защиты информации и информационной безопасности в целом. \r\n \r\nХороший эксперт по кибербезопасности — практик, который знает, как примерно мыслит злоумышленник и какие инструменты киберпреступник может применить. Из всех методик и векторов атак около 80% известны специалистам, что позволяет применяя существующие средства защиты успешно бороться с ними. 20% — это уязвимости нулевого дня, новоизобретенные методы взлома и т.п. Профессионал должен быть всегда начеку для того, чтобы вовремя среагировать.\r\n\r\n\r\nНаиболее важные специальности в ИБ\r\n\r\nЗдесь много возможных вариантов ответа, поскольку специальности можно делить на разные типы и разновидности. Кроме того, можно долго спорить, какие направления в ИБ всех главнее. Поэтому сделаем субъективное выделение трех важных направлений работы:\r\n\r\nПентестер. Мы живем в мире приложений, они везде — в смартфоне, ноутбуке, на стационаре и даже в холодильнике. К сожалению, далеко не все разработчики ПО имеют более-менее продвинутые навыки в информационной безопасности. А если и так, то уязвимость может возникнуть при взаимодействии, например, фронтенда приложения с бэкендом. Ошибки могут быть и в написанном коде. Эксперт, который может подсказать, как защитить приложение или сервис от взлома — весьма ценный специалист.\r\n \r\nПентестер (penetration tester) — по сути, белый хакер. Его задача — исследование безопасности веб-сайтов, мобильных приложений, программных платформ и т.п. В отличие от злоумышленников, которых за их деятельность ждет наказание, пентестеры за обнаружение уязвимости получают бонусы. Среди пентестеров есть и фрилансеры — это, зачастую, охотники за Bug Bounty, вознаграждением, предлагаемым какой-либо компанией за обнаружение уязвимости в ее сервисе или приложении. Кстати, факультет информационной безопасности GeekBrains готовит, в том числе, пентестеров. Об успехах некоторых студентов мы планируем опубликовать отдельную статью.\r\n \r\nСпециалист по безопасной разработке приложений. Такой эксперт уже не просто ищет потенциальные уязвимости используя готовые инструменты или тулзы собственной разработки. Он способен разобраться в коде проектов, написанных на разных языках программирования, определить типовые ошибки кода и указать разработчикам на их наличие. В своей работе специалист использует различные инструменты, использует статический и динамический анализ кода, знает разные инструменты и способен выступать в качестве эксперта для команды разработки. Он может указать разработчикам на потенциально уязвимые части кода, которые необходимо переписать.\r\n \r\nСпециалист по ИБ широкого профиля. Здесь речь о профессионалах, которые могут быть экспертами в 2-3 направлениях информационной безопасности и хорошо разбираться еще в 4-5 смежных направлений. Такие профессионалы могут погружаться в экспертизу и выступать в качестве консультантов или архитекторов сложных высоконагруженных проектов.\r\n\r\n\r\nНу а сколько времени нужно на то, чтобы стать хорошим специалистом?\r\n\r\nЗдесь есть два варианта развития событий. Если в информационную безопасность пришел, например, журналист, который ранее писал о путешествиях, то ему нужно потратить около полутора лет на то, чтобы выйти на уровень джуниора. Это при условии, если в неделю заниматься по 5-7 часов, целенаправленно изучать определенные темы.\r\n \r\nНо если инфобезом решил заняться, например, системный администратор, то ему понадобится гораздо меньше времени. Он уже знает, что и как работает, остается на солидную основу (ее солидность зависит от опыта и времени работы) нанести новые знания и практику. При аналогичных названным выше условиям обучения — 5-7 часов в неделю техническому спецу хватит около полугода на выход на уровень джуниора по ИБ или даже более высокую ступень.\r\n \r\nВ любом случае рекомендуется изучать международные практики, например,  с ISO/IEC 27000 — серией международных стандартов, которые включают стандарты по информационной безопасности, опубликованные совместно Международной Организацией по Стандартизации (ISO) и Международной Электротехнической Комиссии (IEC). Кроме того, передовые практики по ИБ можно найти в стандартах различных институтов. Так, некоммерческая организация MITRE ATT&CK позволяет получить детальную информацию о методах работы киберпреступников — например, как они начинают разведку, затем взламывают один из элементов защиты, проникают и закрепляются в системе. В фреймворке MITRE ATT&CK подробно описывается, как злоумышленники могут выполнить свою задачу, описаны меры противодействия или указываются эффективные способы минимизации ущерба, если взлом все же произошел.\r\n \r\nКак всегда, есть «но». В том случае, если обучение выполняется формально, например, ради оценок, ничего хорошего из этого не получится. Да и знания без практики не сделают из новичка специалиста.\r\n \r\nКонечно, в ходе самостоятельного обучения все инструменты студенты опробовать не могут, но те, без которых не обойтись в дальнейшей работе — осваиваются. Этой основы вполне достаточно джуниору.\r\n\r\n\r\nА какие инструменты используют «безопасники»?\r\n \r\nВсе зависит от того, в каком именно направлении занят специалист, а также от места его работы — коммерческая это организация или государственная. Если говорить о России, то специалистам по информационной безопасности часто приходится работать с сертифицированными ФСТЭК ФСБ инструменты — просто потому, что государственные организации обязаны использовать лишь сертифицированные ПО и железо. Это могут быть отечественные антивирусы, межсетевые экраны, разного рода аппаратное обеспечение.\r\n \r\nСотрудникам коммерческих организаций проще — здесь можно работать с инструментами от Cisco, Palo Alto, других международных или отечественных компаний.\r\n \r\nНовичку в информационной безопасности стоит начать с самостоятельного изучения опенсорс-инструментария, прежде, чем переходить к платным инструментам. Широкий спектр программных продуктов, которые нужны в ежедневной работе, есть в Kali Linux, Parrot OS. Нужно освоить Wireshark, SqlMap, Nmap, John the Ripper и многие другие вещи. \r\n\r\n\r\n \r\nЧто касается компетенций, наиболее необходимыми для начинающего специалиста можно назвать:\r\n\r\nпоиск уязвимостей на клиентской части веб-приложений, эксплуатация клиентских уязвимостей, способы защиты;\r\nНавыки поиска server-side-уязвимостей, понимание особенностей Bug Bounty;\r\nНавыки взлома беспроводных сетей, устройство сетей и способы обеспечения безопасности в них;\r\nНавык реверса приложений, поиска и эксплуатации бинарных уязвимостей. Основы криптографических протоколов.\r\n\r\nКстати, в 2016 году на «Хабре» публиковался усредненный список обязанностей и требований пентестеров.\r\n \r\nОбязанности:\r\n\r\nВыполнение тестирования информационных сред и программных продуктов компании;\r\nТестирование информационных систем на отказоустойчивость;\r\nИнструментальный анализ информационных систем;\r\nВыявление актуальных угроз по классификации OWASP TOP 10, выработка компенсирующих мер;\r\nТестирование на проникновение;\r\nАнализ безопасности исходных кодов программных продуктов.\r\n\r\nТребования:\r\n\r\nОпыт работы по выявлению уязвимостей систем;\r\nОпыт работы с Burp Suite, Hydra;\r\nОпыт работы SQLMap, OpenVAS, Metasploit Framework, Fortify, AppScan;\r\nОпыт работы Acunetix, w3af, X-Spider, Max-Patrol, Nmap;\r\nЗнание принципов построения и работы веб-приложений;\r\nЗнание типовых угроз и уязвимостей веб-приложений, перечисленных в OWASP Top 10;\r\nНавыки ручного и автоматизированного тестирования безопасности веб-приложений;\r\nОпыт проведения тестирования на проникновение;\r\nОпыт проведения аудита систем ИТ и ИБ.\r\n\r\nКак видим, список довольно обширен, и он может быть гораздо большим. Но пугаться не стоит — как правило, потенциальный работодатель стремиться покрыть как максимальный «объём» рынка труда, перед ним не стоит задача «отшить» всех потенциальных кандидатов еще на стадии ознакомления с вакансией. Получить представление о том, что нужно работодателю, можно, ознакомившись с 3-5 реальными вакансиями.\r\n\r\nВот несколько примеров — реальные вакансии на сервисе «Мой круг». \r\n\r\nimage\r\n\r\n\r\nСколько получает эксперт по ИБ?\r\n \r\nРазброс зарплат довольно большой, как обычно, все зависит от региона  и специальности. Но оплата труда специалиста по информационной безопасности сейчас достойная, а ее размер понемногу увеличивается. Во многом рост обусловлен кадровым «голодом» в сфере ИБ.\r\n \r\nДля понимания уровня зарплат специалистов стоит ознакомиться с данными зарплатного калькулятора «Моего круга».\r\n\r\nimage\r\n \r\nСтажеру-джуниору можно надеяться на диапазон от 35 тыс. руб. до 60-70 тысяч.\r\n\r\nСредний уровень для миддла — от 60-70 тысяч до 80 тыс. руб. Кстати, пентестер может рассчитывать на зарплату от 100 тысяч, если есть хотя бы небольшой опыт реальной работы и хорошая подготовка.\r\n\r\nДальше уже идут «универсальные солдаты», которые знают языки программирование, могут писать скрипты, обладают знаниями в смежных сферах. Их зарплата начинается от 100 тысяч и может доходить до 300-500 тыс. руб. Но таких предложений на рынке не очень много, плюс чтобы достичь подобного уровня заработной платы, нужно быть очень, очень хорошим специалистом. За экспертизу готовы платить многие компании.\r\n \r\nВ целом же в таких городах, как Москва, Питер и Новосибирск можно рассчитывать на 60-120  тысяч рублей.\r\n \r\nЗавершая статью, стоит сказать, что защита информации — приоритетное направление ИТ-рынка. Несмотря на явный прогресс инструментов автоматизации, технологий искусственного интеллекта, на переднем краю информационной защиты все же находится человек. На хороших специалистов спрос есть всегда, а по мере роста кадрового голода в ИБ-сфере предложения становятся все более интересными.','2019-08-23 22:05:03',NULL,1),
(8,'Chaos engineering','Последнее, что хочется увидеть во время дебага кода — это хаос. Но что если этот хаос управляемый и запущен руками самого разработчика? Зачем умышленно устраивать турбулентность в слаженной работе своего приложения, как добиться душевного спокойствия при релизе важных фич и где точно вам пригодится практика хаос-инженерии, читайте в разговоре ведущих подкаста AppsCast с Павлом Осиповым PavelOsipov.\r\n\r\n\r\n\r\nАлексей Кудрявцев: Всем привет! Сегодня у нас в гостях Павел Осипов из Облака Mail.ru, с которым мы поговорим о chaos engineering.\r\n\r\nПавел Осипов: Всем привет! Я лет шесть руковожу разработкой Облака Mail.ru. За это время мы накопили много практик эконом-тестирования и одна из них — chaos engineering. Такая практика позволяет проводить серию контролируемых экспериментов по выявлению работоспособности вашей системы в условиях враждебного окружения. По итогам этих опытов вы получаете полезные инсайты. Например, вы вряд ли регулярно смотрите, как ведет себя система в условиях нестабильной сети. Если ваш пользователь часто ездит в метро или отдыхает в условиях гостиничного вайфая, сеть не так стабильна как на рабочем месте программиста. После каждого своего отпуска на море я привожу целый «портфель» логов о том, что пошло не так с приложением.\r\n\r\nЛично мне разведение ручного хаоса позволяет получить дополнительную дозу уверенности, что все будет идти хорошо, даже если вовне приложения все плохо.\r\n\r\nЕсть ситуации, когда я доверяю ручному хаосу больше, чем автоматическим тестам.\r\n\r\nЗрим в корень хаоса\r\n\r\nАлексей Кудрявцев: Откуда корни такой практики?\r\n\r\nПавел Осипов: Это серверная практика, где проблем в разы больше. Мы привыкли к понятию технического долга, а на Западе есть еще dark debt — скрытый долг, который неизбежно возникает в сложных системах. В отличие от технического долга, где мы осознанно заимствуем время себя будущего у себя настоящего, скрытый долг невидим на этапе создания системы. Он возникает на стыке компонентов или hardware и software и может повлечь за собой каскад проблем: что-то ломается на одном компоненте, накладывается на другой, и вот система лежит целиком.\r\n\r\nНапример, в 2016 году из-за каскадного отключения баз данных 2,5 часа лежал Facebook. Тогда система, которая проверяла валидность конфигурационных файлов, начала их по ошибке удалять, причем не только в кэширующей подсистеме, но и в той базе данных, которая была первичным источником.\r\n\r\nМне очень нравится интервью с Олегом Анастасьевым из Одноклассников о проведении учений по предотвращению инфраструктурных аварий. У них три дата-центра, которые должны быть в боеготовности 24/7, но раз в квартал случается какой-нибудь отказ. Такие учения они проводят на продакшене. С одной стороны, это кажется страшным, так как если произойдет что-то непредсказуемое, ляжет весь дата-центр и не будет доступен на проде. Но с другой стороны, этот процесс контролируемый и если что-то пойдет не так, то вы это сразу увидите, остановите, и все восстановится. Если такое произойдет в условиях боевой жизни, то включить обратно просто так не получится, а разбор причин отключения затянется надолго.\r\n\r\nПольза хаоса в мобильной разработке\r\n\r\nДаниил Попов: Пока речь про серверную разработку, где популярны микросервисы и возможно каскадное отключение. Можешь привести еще примеры, что проверять через chaos engineering в мобильной разработке?\r\n\r\nПавел Осипов: Мой любимый пример — разлогины приложений. В тестовых условиях наши действия могут быть очень щадящими по отношению к приложению: зашли в настройки аккаунта, нажали кнопку «выйти», приложение вышло и при просмотре экрана логина вроде бы все хорошо. У пользователей часто бывают более экзотические ситуации. Например, клиент поменял через веб-интерфейс пароль или произошло большое количество разлогинов на других устройствах и refresh token вытеснился. Этот разлогин случается не в окне с аккаунтом пользователя, а, например, в момент работы полноэкранного просмотрщика фотографий.\r\n\r\nМы нашли множество ситуаций, когда разлогины в разных местах приложения приводят к таким последствиям как утечки памяти. Тот же просмотрщик с completion-блоком мог прихватить жизненно важный сервис, который в итоги утек.\r\n\r\nУсловия мы моделируем с помощью хаос-инженерии. В системе есть сервис, который прозрачно для прикладных высокоуровневых сервисов обновляет access-токен приложения с помощью refresh-токена приложения. Мы внедрили хаос, при котором сервис вместо обновления токена с определенной долей вероятности портит его, а каждый разработчик несколько раз в день сталкивается с разлогином в неожиданном месте.\r\n\r\nБлагодаря этому мы открыли интересное поведение UIKit в iOS: если при пересвечивании рутованного ViewController’а на окне модально запрезенчено другое окно, то рутованный ViewController утекает и остается жить в системе навеки вечные. Если при этом ViewController имел ссылку на сервисы, которые по логике архитектуры обязаны существовать в системе в одном экземпляре, то проблем не избежать. Например, в Облаке есть сервис автозагрузки фотографий, и, если в системе останется жить два таких сервиса, они будут выполнять кучу ненужной работы и посадят батарею устройства в два раза быстрее чем положено.\r\n\r\nЕще курьезный случай. При появлении iOS 8 были проблемы с extensions: на некоторых устройствах, когда все permissions в настройках приложения были даны, на старте система заявляла, что в shared app group у приложения доступа нет.\r\n\r\nТипология хаоса\r\n\r\nДаниил Попов: Хаос вносится в систему автоматизировано на основе процентов или конфига, но нужен ли взгляд человека, чтобы понять, что пошло не так?\r\n\r\nПавел Осипов: Хаос бывает разным: и ручным, и автоматическим. В случае с операционной системой, которая говорила, что у приложения нет доступа к shared app group, и extensions не могли получить доступ к общим ресурсам и базе данных, использовался ручной хаос, который включался с помощью галочки в системных настройках приложения. Это легко могли смоделировать ребята из QA-команды.\r\n\r\nЕсть автоматизированный хаос. В частности, это ошибки, которые моделируются из микросервисов нашего бэкенда, и хаос, связанный с обновлением токена. Последствия бывают разные. Поехавшую верстку можно определить через визуальное наблюдение. Есть места, которые позволяют выявлять аномалии в автоматическом режиме. Например, у нас в приложении автоматически определяются утечки памяти. В системе есть два IoC-контейнера. Один менеджерит время жизни глобальных сервисов, которое совпадает с временем жизни самого приложения, другой контейнер менеджерит сервисы, совпадающие во времени жизни с юзером. Каждый IoC-контейнер, создавая сервис, проверяет, что тот существует в одном экземпляре.\r\n\r\nВернемся к примеру с разлогинами. В каком-то месте внезапно произошел разлогин и разработчик для продолжения работы заново вошел в аккаунт. В этот момент IoC-контейнер сообщает, что произошла утечка памяти, и сервис, который в теории должен существовать в одном экземпляре, обнаружен еще раз.\r\n\r\nКогда приходит время хаоса?\r\n\r\nАлексей Кудрявцев: Что послужило триггером для внедрения практики?\r\n\r\nПавел Осипов: Мы пришли к этому через необходимость удешевлять тестирование. Как можно побороться с теми же проблемами разлогина? Можно написать unit-тесты на утечки, можно заморочиться и написать UI-тесты.\r\n\r\nХаос-инжиниринг — самая дешевая практика, так как он не завязан на юзкейсы, а действует автоматизировано для всех юзкейсов сообща.\r\n\r\nВторой триггер — до внедрения практики в нашем crash-report часто наблюдались похожие крэши с одинаковой корневой причиной. Например, что крэш произошел не из-за разлогина системы в профиле, а из-за того, что пользователь пролистывал в это время галерею фотографий. Ситуации разные, и невозможно протестить все комбинации разлогинов. Вот и захотелось придумать то, что автоматизирует процесс.\r\n\r\nУ хаос-инженирии есть родственная практика — мутационное тестирование. В этой практике мы изменяем маленькие кусочки кода и смотрим, как это влияет на тесты. Если после изменения тесты выполняются корректно, значит, для этих фрагментов кода тестов недостаточно.\r\n\r\nОтличие хаос-инжиниринга от мутационного тестирования в том, что мы автоматизировано меняем не сам продакш-код, а его окружение.\r\n\r\nАлексея Кудрявцев: Можно ли было локализовать причину и пофиксить без chaos engineering?\r\n\r\nПавел Осипов: Нет единой причины, которая провоцирует крэшы. Каждый случай по-своему уникален. Например, модальная кнопка оказалась поверх окна, и это привело к тому, что во время разлогина утек рутованный ViewController. Предусмотреть все комбинации иерархии окон, которые у вас есть во время разлогина, невозможно. Chaos engineering локализовал паттерны, при которых происходят утечки и крэши.\r\n\r\nАлексей Кудрявцев: Как долго вы уже используете эту практику?\r\n\r\nПавел Осипов: Мы начали её использовать на заре проекта в 2012 году, потому что разрабатывать надо было быстро, а времени на широкомасштабное тестирование не выделялось. При этом это не только внушительный, но и позитивный опыт.\r\n\r\nДаниил Попов: Если у меня в приложении что-то крэшнулось и надо завести в JIRA задачу, что починить в будущем, как эту ситуацию воспроизвести?\r\n\r\nПавел Осипов: Нет универсального рецепта. Chaos engineering активируется в момент дебага приложения и деактивируется в момент сборки релизной версии, поэтому такие ситуации можно увидеть через логи в консоли среды разработки, из которых можно прикинуть, как поставить таску в JIRA.\r\n\r\nАлексей Кудрявцев: Пытаетесь ли создать воспроизводимое поведение, чтобы ваша система хаоса оповещала о проблемных состояниях и предлагала внести в конфиг на старте, чтобы это состояние повторить?\r\n\r\nПавел Осипов: Звучит космически и возможно в архитектурах типа Redux. Если архитектура позволяет записывать все действия, которые предваряли критические события, тогда это возможно. У нас не так. Такое практиковалось в мою бытность работы serverside-программистом в телекоме. Там были тесты, которые рандомизировали вход на подсистему и проверяли адекватный выход. Мы добились того, когда тест с рандомным входом крэшил систему, а в программе, которая отвечала за автоматизацию тестирования, откладывались все необходимые параметры входного запроса, чтобы можно воспроизвести.\r\n\r\nПрименяем хаос в приложении\r\n\r\nДаниил Попов: Правильно, что такой хаос вносится в код руками?\r\n\r\nПавел Осипов: Да, в нашем сетевом клиенте встроена функциональность, куда можно подать конфиг, где описан параметр хаоса, который должен воспроизводится. На основании конфига он решает запроксировать клиентский запрос на сервер или самостоятельно ответить ерундой. Слой для работы с сетью таков, что можно кастомизировать хаос, который привносится микросервисом в бекенде. Бессмысленно моделировать ошибки невалидности авторизационных данных, если запросы микросервиса не требуют авторизации.\r\n\r\nМы не просто рандомизируем все подряд, играем в идеальный код, а осмысленно рандомизируем то, что в реальной жизни сможет воспроизвести пользователь.\r\n\r\nАлексей Кудрявцев: Что вы рандомизируете кроме сети и файлов?\r\n\r\nПавел Осипов: Мы отлаживали практику по рандомизации ответов от конкретных эндпоинтов, чтобы смоделировать поведение и хаос каждого микросервиса в отдельности. У нас закончена работа по выносу файловой системы в отдельные подсистемы, и я пробую моделировать разного рода ошибки при попытке приложения записать или считать файл. Вручную моделируется доступ к shared app group в приложении, и очень хочется начать моделировать поведение приложения, когда она стартует с экстремально малым дисковым пространством, при котором невозможно даже базу данных создать.\r\n\r\nАлексей Кудрявцев: Это все, чем вы занимаетесь?\r\n\r\nПавел Осипов: В принципе да. Мы еще не разгребли все те баги, которые найдены с помощью существующего хаоса. Конечно, интересно повышать хаос и переносить на другие подсистемы, но тогда мы не будем успевать фиксить столько, сколько хаос будет находить.\r\n\r\nГде вообще место хаоса? Всегда же можно найти место, где можно создать очередную турбулентность для приложения. Важно отталкиваться от проблем. Мы сделали хаос для разлогинов, потому что наблюдали большое количество сходных проблем.\r\n\r\nЕсли мониторинг показывает, что в других подсистемах особых проблем не возникает, то нет смысла тратить время на моделирование непредвиденных обстоятельств.\r\n\r\nЭто не касается биллинга, где важна корректная работа.\r\n\r\nАлексей Кудрявцев: С другой стороны, мы не в курсе, что творится у пользователей — это сам по себе хаос, потому что ты не знаешь, куда его встроить, а куда нет, и остается только его симулировать.\r\n\r\nПавел Осипов: Всегда нужно смотреть на ROI. Конечно, можно воспроизвести и самые экзотические кейсы, но если они единичны, то, возможно, и не являются критичными, и нет смысла их моделировать.\r\n\r\nСложности внедрения хаоса\r\n\r\nАлексей Кудрявцев: Что из уже сделанного вам далось легко, а что вызвало трудности?\r\n\r\nПавел Осипов: Привыкание к хаосу — это необычно для новичка, так как это не повсеместно применяемая практика. Сложно адаптироваться к тому, что у тебя куча ошибок. Почти на каждом экране можно получить пачку «пятисоток» или непонятных «404-х», сервер отвечает через раз. Только со временем привыкаешь, что все это бурления, и ответы от сервера моделируются самой системой.\r\n\r\nТяжело, когда у тебя критичная фича, которая уже горит, и нужно поскорее закончить, а тут внезапно выскакивает разлогин в месте скопления запросов. Тебе, например, нужно корректно выполнить верстку экрана и нужно, чтобы все запросы завершились успешно, а это настолько маловероятно, что приходится заходить несколько десятков раз, чтобы добиться нужного состояния. В таких случаях контрмерой становится отключение хаоса, и важно не забыть его потом снова включить.\r\n\r\nЕще момент, который вызывает недовольства, это использование хаоса в инфраструктурных сервисах с большим количеством сайд эффектов.\r\n\r\nДаниил Попов: Получается, у разработчиков на дебаге всегда по умолчанию включен хаос?\r\n\r\nПавел Осипов: Совершенно верно. Временами, когда тебе вообще не до хаоса и тех экзотических ситуаций, которые он тебе может воспроизвести, это раздражает. Приходится терпеть, но всегда можно отрегулировать уровень хаоса, если твой экран интенсивно работает с сетью. С другой стороны, хаос может выявить проблему далеко не в том месте, где ты ее ищешь, и не у того разработчика, который эту фичу разрабатывает. Бывает, твоя фича, в которую добавлен хаос, приводит к последствиям, которые влияют на фичу твоего коллеги. Об этом и не узнаешь, если хаос будет включен только в конкретный момент разработки.\r\n\r\nСмысл хаоса в том, чтобы выявлять непредвиденные последствия при взаимодействии большого количества компонентов.\r\n\r\nЕсли включать хаос дозированно и точечно, то эти редкие, но меткие выстрелы будут незаметны.\r\n\r\nДаниил Попов: Не мешает ли хаос читабельности кода?\r\n\r\nПавел Осипов: Когда хаос внедряется вне системы, прилепляется к готовой, то да, это выглядит неаккуратно. У нас, за счет долгого опыта использования, хаос органично вплетен в систему и изолирован настолько, что ты не замечаешь его в коде.\r\n\r\nАлексей Кудрявцев: Вы отлавливаете много редких кейсов, фиксите их, и код обрастает костылями. Не усложняет ли это логику приложения?\r\n\r\nПавел Осипов: Это всегда большая часть нашего кода, но иначе крупные продакшн-приложения и не пишутся. Конечно, все зависит от мастерства разработчика, который умеет исправлять код так, чтобы это не мозолило глаза.\r\n\r\nПлюсы внедрения хаоса\r\n\r\nДаниил Попов: Есть ли количественные показатели, которые улучшились после внедрения chaos engineering?\r\n\r\nПавел Осипов: Для меня самая главная метрика — это внутреннее душевное спокойствие, когда я отправляю фичу в релиз.\r\n\r\nАлексей Кудрявцев: Бизнесу душевное спокойствие не продашь. Чем аргументировать внедрение хаос-инженерии в компании?\r\n\r\nПавел Осипов: Chaos engineering высвобождает время тестировщиков, так как появляются автоматические тесты. Те же крэши с разлогинами после внедрения практики хаоса практически исчезли из нашей JIRA.\r\n\r\nХаос-инженерия благотворно влияет на релизный цикл, так как ты получаешь быструю обратную связь. Одно дело, когда готовая фича уходит в тестирование, и через длительное время тебе сообщают о количестве найденных багов, совсем иначе, когда у вас есть робот-тестер, который работает на протяжении всего дебага программы.\r\n\r\nУ меня ощущение уверенности от результатов unit-тестов намного ниже, чем от включенного на 50% хаоса при загрузке тысячи файлов. При такой загрузке все самые невероятные комбинации точно будут зафиксированы.\r\n\r\nУ кого учиться и с чего начать?\r\n\r\nАлексей Кудрявцев: Какие инструменты вы для этого использовали? Взяли открытые библиотеки или сами написали и выложили в open source?\r\n\r\nПавел Осипов: Мы выложили в open source сетевую библиотеку, а специализированных инструментов и нет. Единственный, который я знаю — Netflix Chaos Monkey, который рандомно «бегает» по AWS instance и терминирует их, смотрит, все ли пошло хорошо, если определенное число контейнеров погашено. Я считаю, что написание конфигов там, где вы соприкасаетесь со смежными системами, не требует глубокой автоматизации.\r\n\r\nДаниил Попов: Где подробнее почитать про chaos engineering?\r\n\r\nПавел Осипов: Во-первых, сайт Principles of Chaos, на который ссылаются все ресурсы по этой теме. Во-вторых, книги Learning Chaos Engineering и Chaos Engineering Observability.\r\n\r\nВообще, хаос-инженерия — это практика здравого смысла и фундаментальных знаний там нет. Всегда нужно понимать, в каких местах внедрять хаос. В тоже время хаос для каждого приложения уникален? и нужно сначала понять, что нужно внедрять именно у вас.\r\n\r\nАлексей Кудрявцев: С чего начать, если ты все-таки решился внедрить хаос?\r\n\r\nПавел Осипов: Начните с анализа проблем в системе, какие крэши и почему возникают. После выявления корня зла необходимо понять, как смоделировать ситуации, которые приводят к проблемам. А третьим шагом аккуратно внедрить хаос и держать его под контролем.\r\n\r\nАлексей Кудрявцев: Болеть в приложении может многое, но как приоритизировать? Куда лучше не соваться?\r\n\r\nПавел Осипов: Нет нереальных вещей. Важно соотношение цены и выхлопа. Если есть богатый системный API, то обкладывать его своими обертками дорого. Если ты что-то не до конца понимаешь, то начнешь провоцировать хаос, который в природе невозможен и приведет к бесполезной борьбе. Например, если весь UIKit или API с покупками покрыть хаосом.\r\n\r\nХаос — это не рандомное тыканье на клавишу, а четкое понимание моделируемых ситуаций.\r\n\r\nАлексей Кудрявцев: Насколько ты советуешь эту практику внедрять?\r\n\r\nПавел Осипов: Я вообще советую начинать именно с внедрения хаос-инженерии, а не unit-тестов, так как это самая дешевая практика.','2019-08-23 22:06:19',NULL,1),
(9,'Python-скрипт на 20 строк, который каждый день желает родителям доброго утра через WhatsApp','Автор материала, перевод которого мы сегодня публикуем, говорит, что современные люди, жизнь которых переполнена работой, часто забывают писать сообщения своим родным и близким. Он, глядя на то, как его родители каждое утро шлют ему в WhatsApp вдохновляющие цитаты и полезные советы о здоровье, решил, что пришло время ответить им взаимностью.\r\n\r\nВ этом руководстве мы напишем простой Python-скрипт, предназначенный для отправки WhatsApp-сообщений. В ходе работы будем пользоваться Python-пакетом Twilio. Для организации ежедневного запуска скрипта в заданное время разместим код в облаке.\r\n\r\n\r\n\r\nОдним из подходов к решению этой задачи является использование Python-пакета Selenium и веб-версии WhatsApp вместо сервиса Twilio, на который, после исчерпания возможностей бесплатного предложения, нужно оформлять платную подписку. Но так как работа с веб-версией WhatsApp требует периодического сканирования QR-кода с помощью мобильного телефона, автоматизировать отправку сообщений при таком подходе не получится.\r\n\r\nРабота над проектом будет состоять из трёх шагов:\r\n\r\nНастройка Twilio.\r\nИзучение и модификация кода.\r\nРазвёртывание проекта в облаке и настройка триггера.\r\n\r\nШаг 1. Настройка Twilio\r\n\r\nСоздадим бесплатную учётную запись на сайте Twilio, подтвердим адрес электронной почты и номер телефона.\r\n\r\n\r\n\r\nРегистрация учётной записи Twilio\r\n\r\nКроме того, в рамках бесплатного предложения Twilio необходимо использовать WhatsApp-песочницу (WhatsApp Sandbox). Это означает, что вы не сможете пользоваться собственным номером телефона, и то, что вам придётся пройти через процедуру выдачи разрешения на получение WhatsApp-сообщений.\r\n\r\nСобственным номером для работы с сообщениями можно пользоваться после того, как WhatsApp разрешит Twilio использовать ваш номер. Для того чтобы получить разрешение, нужно заполнить форму. Из материалов техподдержки Twilio можно узнать о том, что, хотя Twilio и работает напрямую с WhatsApp, на получение разрешения может понадобиться некоторое время. К тому же, там говорится об ограниченных масштабах выдачи разрешений. В результате многим приходится пользоваться WhatsApp-песочницей Twilio.\r\n\r\nВсё это особой радости не вызывает, но то, что доступно нам в рамках бесплатного предложения Twilio, позволяет решить нашу задачу. Кроме того, получается, что WhatsApp-песочница — это пока единственный широкодоступный вариант.\r\n\r\nТеперь нужно подключить телефон получателя сообщений к песочнице, после чего на этот телефон можно будет отправлять сообщения. Для того чтобы узнать о том, как это сделать, вам нужно перейти в раздел консоли Twilio, который посвящён WhatsApp. В частности, тут предлагается отправить WhatsApp-сообщение с указанным текстом на определённый номер. \r\n\r\n\r\n\r\nСтраница консоли Twilio с инструкциями по подключению телефона, на который можно будет отправлять сообщения\r\n\r\n\r\n\r\nЗапрос на подключение, отправленный с телефона\r\n\r\nСохраните выданный вам WhatsApp-номер в контактах. Ему можно назначить любое имя. Я, чтобы не усложнять себе жизнь, назвал этот контакт Twilio Sandbox, а потом отправил на него сообщение с телефона отца (это можно видеть на предыдущем рисунке). Эта процедура выполняется лишь один раз.\r\n\r\nТеперь нужно перейти в консоль Twilio и получить SID и токен аутентификации для своей учётной записи. Эти данные помогут Twilio узнать вас при программной работе с сервисом.\r\n\r\nШаг 2. Изучение и модификация кода\r\n\r\nЗагрузите этот GitHub-репозиторий и распакуйте архив.\r\n\r\n\r\n\r\nСодержимое zip-файла\r\n\r\nЗдесь вы найдёте файл с исходным кодом (whatsapp_messaging.py) и пакет для развёртывания проекта (aws_lambda_deploy.zip).\r\n\r\nВот код скрипта:\r\n\r\nfrom twilio.rest import Client\r\n\r\ndef msg_mom_and_dad(event=None, context=None):\r\n\r\n    # тут нужно использовать SID и токен аутентификации, которые вы получили на Twilio\r\n    twilio_sid = \'AC84c9f1602d7fb6af4eda5b0c39a03b37\'\r\n    auth_token = \'4a2021b28f1aa606d9c6945d3c248ebd\'\r\n\r\n    whatsapp_client = Client(twilio_sid, auth_token)\r\n\r\n    # в этот словарь можно добавлять контактные сведения тех,\r\n    # кому вы хотите отправлять сообщения\r\n    contact_directory = {\'daddy\':\'+919624666836\'}\r\n\r\n    for key, value in contact_directory.items():\r\n        msg_loved_ones = whatsapp_client.messages.create(\r\n                body = \'good morning {} !\'.format(key),\r\n                from_= \'whatsapp:+14155238886\',\r\n                to=\'whatsapp:\' + value,\r\n\r\n            )\r\n\r\n        print(msg_loved_ones.sid)\r\n\r\nСейчас мы разберём этот код. Вот, для удобства, скриншот с пронумерованными строками.\r\n\r\n\r\nКод файла whatsapp_messaging.py с пронумерованными строками\r\n\r\nСтрока 1. Импорт клиента для работы с REST-API Twilio.\r\nСтрока 3. Создание функции msg_mom_and_dad. Эту функцию мы передадим AWS. Она будет вызываться ежедневно в заданное время.\r\nСтроки 6-7. Здесь вам нужно заменить существующие в коде sid и auth_token на собственные (об их получении мы говорили в конце предыдущего раздела).\r\nСтрока 9. Создание объекта клиента Twilio с использованием учётных данных.\r\nСтрока 13. Создание словаря. В качестве ключа тут используется имя получателя сообщений, в качестве значения — номер его телефона. В этот словарь можно добавить и дополнительные контактные сведения.\r\nСтрока 15. Цикл for, в котором осуществляется обход словаря (в нём пока имеется лишь одна запись). В body нужно указать текст сообщения. Я создал простое сообщение с текстом «good morning», за которым следует значение, взятое из ключа текущего элемента словаря. В моём случае это приводит к формированию сообщения «good morning daddy !». Во from_ указывается тот WhatsApp-номер, который мы получили ранее. В to записывают номер получателя сообщения — тот, с которого ранее отправляли запрос на подключение к WhatsApp-песочнице Twilio.\r\nСтрока 23. Тут мы, в целях проверки состояния сообщения, выводим его SID. Мы этими сведениями пользоваться не будем.\r\n\r\nВам, чтобы воспользоваться этим кодом для отправки сообщений, нужно изменить в нём следующее:\r\n\r\ntwilio_sid\r\nauth_token\r\ncontact_directory\r\nfrom_\r\nbody (это необязательно)\r\n\r\nПосле того, как вы внесёте в код изменения, сохраните файл. Затем распакуйте архив aws_lambda_deploy.zip, замените файл whatsapp_messaging.py на ваш файл с тем же именем, после чего снова упакуйте всё в .zip-архив. Смысл этих действий сводится к тому, чтобы внести в код ваши учётные данные и сведения о тех, кому вы хотите отправлять сообщения. Всё остальное в пакете, предназначенном для развёртывания на AWS, осталось неизменным. Теперь займёмся работой с AWS.\r\n\r\nШаг 3. Развёртывание проекта на AWS и настройка триггера\r\n\r\nКод готов к запуску и к тому, чтобы отправлять WhatsApp-сообщения. Если вы интересуетесь тем, какую роль в проекте играют другие файлы из архива aws_lambda_deploy.zip, то знайте, что среди этих файлов находятся пакет Twilio и все остальные зависимости проекта. Всё это нам нужно из-за того, что мы планируем использовать функции AWS Lambda в Python-окружении, в котором нет пакета Twilio. А почему бы нам это не исправить, просто выполнив для установки нужного пакета команду pip install twilio? Дело в том, что тут у нас нет сервера.\r\n\r\nДля этого мы используем AWS Lambda — это бессерверная вычислительная среда, в которой можно размещать фрагменты кода, вызов которых, в соответствии с нуждами пользователя, инициируют различные события и триггеры. Наш код планируется запускать всего раз в день, поэтому использование чего-то вроде EC2-сервера на AWS, работающего круглосуточно, окажется пустой тратой вычислительных ресурсов и денег. Наша Lambda-функция будет вызываться ежедневно в определённое время по запросу из триггера, а её выполнение будет занимать совсем немного времени.\r\n\r\nНачало создания Lambda-функции\r\n\r\nВойдите в свою учётную запись AWS. После этого пройдите по пути Services → Compute → Lambda → Create a function.\r\n\r\n\r\n\r\nЭкран создания Lambda-функции\r\n\r\nДадим функции имя.\r\n\r\nВ качестве окружения, в котором будет выполняться функция, выберем Python 3.6. Нам не нужно подключаться к другим сервисам AWS. Поэтому нас устроит уровень разрешений, задаваемый вариантом Create a new role with basic Lambda permissions.\r\n\r\nПосле выполнения настроек достаточно нажать на кнопку Create function. Теперь мы окажемся на главной панели управления.\r\n\r\n\r\n\r\nПанель управления\r\n\r\nЗдесь, в разделе Function code, нужно указать обработчик (Handler), с помощью которого система сможет запускать наш код. В нашем случае в поле Handler нужно записать строку whatsapp_messaging. msg_mom_and_dad, указав имя файла с кодом и функцию, которую мы хотим вызывать.\r\n\r\nВ поле Function package нужно загрузить наш .zip-файл, то есть — тот файл, который мы создали на предыдущем шаге.\r\n\r\nТеперь код готов к запуску. Проверить — работает ли функция и отправляет ли она сообщения, можно, нажав на кнопку Test.\r\n\r\nФинальным шагом нашей работы станет настройка триггера, который будет вызывать функцию ежедневно в заданное время. Пройдите по пути Add trigger → CloudWatch Events.\r\n\r\n\r\n\r\nНастройка триггера\r\n\r\nНам нужно создать новое правило (Rule). Ему необходимо назначить имя (Rule name). При желании можно добавить к нему описание (Rule description).\r\n\r\nУкажем тип правила (Rule type) как Schedule expression.\r\n\r\nВремя вызова функции задаётся с помощью конструкции cron(30 1 * * ? *). Разберём эту конструкцию:\r\n\r\n30 1 означает UTC-время 1:30 утра. Это — 7 утра по моему IST-времени.\r\nСледующие два символа, * *, служат для указания дня месяца и месяца.\r\nСледующие два символа, ? *, позволяют указать день недели и год. Эта конструкция означает, что функция будет вызываться ежедневно, без ограничений по годам и месяцам.\r\n\r\nЗдесь вы можете узнать о том, как настраивать собственные задания cron.\r\n\r\nПосле того, как настройка триггера завершена, проверьте — установлен ли флажок Enable trigger, включающий триггер. Теперь осталось лишь нажать на кнопку Add и триггер будет создан.\r\n\r\n\r\n\r\nСведения о триггере\r\n\r\n\r\n\r\nСведения о Lambda-функции\r\n\r\nНа панели управления Lambda-функции можно видеть, что к функции прикреплена сущность CloudWatch Events, и то, что функция может вызываться по срабатыванию соответствующего триггера.\r\n\r\nИтоги\r\n\r\n\r\n\r\nСообщение, отправленное Python-скриптом\r\n\r\nМы завершили работу над проектом. Теперь можно, в телефоне получателя сообщений, в контактах WhatsApp, поменять имя контакта Twilio Sandbox на собственное (я поменял его на Son). Наша система, кроме того, позволяет общаться с получателем сообщений из панели управления Twilio.\r\n\r\nУважаемые читатели! Используете ли вы Twilio в своих проектах?','2019-08-23 22:06:59',NULL,1),
(10,'Спросите Итана: как будет выглядеть наша первая прямая фотография землеподобной экзопланеты?','За последнее десятилетия, в основном благодаря миссии Кеплер, наши знания касательно планет других звёздных систем чрезвычайно сильно увеличились. От всего нескольких миров – в основном массивных, с быстрыми, внутренними орбитами, вращающихся вокруг звёзд с небольшой массой – к буквально тысячам планет совершенно разных размеров. Теперь мы знаем, что миры размером с Землю и чуть побольше встречаются чрезвычайно часто. Обсерватории из следующего поколения, которые появятся как в космосе (например, телескоп Джеймса Уэбба), так и на земле (ГМТ и ELT), смогут напрямую сфотографировать ближайшие из этих миров. Как же они будут выглядеть? Об этом спрашивает наш читатель:\r\nКакого рода разрешение можно ожидать от этих фото? Несколько пикселей, или каких-нибудь видимых подробностей?\r\n\r\nСами по себе фотографии не будут очень впечатляющими. Однако из них мы сможем узнать всё, о чём можно мечтать (в разумных пределах).','2019-08-23 22:07:52',NULL,1),
(11,'Небольшой мод превращает «Теслу» в станцию видеонаблюдения','Правительства многих стран разворачивают системы слежки за населением через сеть видеокамер. Но граждане могут использовать этот инструмент и в своих целях.\r\n\r\nИсследователь безопасности Трумэн Кейн (Truman Kain) на хакерской конференции DEF CON представил любопытный мод для автомобиля Tesla под названием Surveillance Detection Scout (слайды презентации, демо). С его помощью автомобиль превращается в настоящую платформу видеонаблюдения на колёсах. Он распознаёт номера машин на дороге и лица людей в реальном времени.\r\n\r\nХакер объясняет, что систему можно использовать в различных целях: как для разведки, так и для контрразведки. Например, если система часто замечает один и тот же автомобильный номер или одного и того же человека — хозяину отправляется сообщение о подозрительной активности. Кто-то может планировать угон автомобиля, ограбление близлежащего дома или что-то подобное.\r\n\r\nВ самом деле, автомобиль Tesla оборудован аппаратным и программным обеспечением, функциональность которого выходит далеко за рамки автопилота:\r\n\r\nТри встроенные камеры с почти круговым обзором\r\nПолнофункциональные API\r\nРежим Sentry Mode (всегда включён): если автомобиль фиксирует вокруг себя движение, то автоматически начинает запись со всех камер.\r\nВстроенный веб-браузер\r\n\r\nНаблюдение идёт в реальном режиме времени. Surveillance Detection Scout высылает предупреждения примерно такого вида: «Серебристый Mercedes-Menz C300 следует за вами в течение 7 минут».\r\n\r\n\r\n\r\n\r\nКонтрразведка\r\n\r\nАвтор приводит два типичных сценария контрразведывательной деятельности:\r\n\r\nВо время парковки: какие автомобили/люди ходят рядом с вашим автомобилем/домом?\r\nНа ходу: как долго определённый автомобиль следует за вами? Встречался ли он раньше?\r\n\r\nПрограмма-скаут отвечает на эти вопросы.\r\n\r\n\r\nSurveillance Detection Scout показывает на карте, какой автомобиль двигался рядом\r\n\r\n\r\nПрограмма извлекает из архива кадры с этим автомобилем\r\n\r\nРазведка\r\n\r\nВ какое время цель пришла домой или покинула офис?\r\nВ какое время мимо здания проходят патрули охраны? В какое время оно пустует?\r\n\r\nЕсли раньше для наружного наблюдения возле дома/офиса цели должен был дежурить агент, то теперь можно оставить пустой автомобиль, он всё для вас сделает.\r\n\r\nЕсть некоторые сомнения, что подобная деятельность вписывается в законы Российской Федерации. Но активация видеорегистратора во время парковки — это штатная функция автомобиля Tesla, так что вряд ли здесь речь идёт о запрещённых «скрытых шпионских устройствах».\r\n\r\nНа GitHub лежит программа Tesla USB, которая позволяет владельцам Tesla копировать видео с автомобиля на внешний диск. Остаётся только обработать видео, что вроде бы не противоречит законодательству.\r\n\r\nПо действующим законам, скрытые видеокамеры/диктофоны запрещены в нестандартных гаджетах, но разрешены в смартфонах или фотоаппаратах, потому что там они являются штатной функцией. То же самое и с автомобилем, хотя на всякий случай лучше проконсультироваться с юристами, которые знакомы с правоприменительной практикой в России. В любом случае, прецедентов пока не было.\r\n\r\nSurveillance Detection Scout задействует видеопоток со штатных видеокамер Tesla и обрабатывает их на собственном оборудовании, которое подключается к бортовому компьютеру. Оборудование можно выбрать в зависимости от ваших потребностей на любой бюджет:\r\n\r\nPi Zero W: 10 долларов США\r\nPi 4B (4 ГБ RAM): 55 долларов США\r\nJetson Nano: 100 долларов США\r\nJetson Xavier: 700 долларов США\r\n\r\nКонечно, производительность отличается на порядки:\r\n\r\n\r\n\r\nКомпьютер помещается в консоль Tesla Model S или Model 3 и подключается к USB-порту приборной панели. Бэкенд реализован на MongoDB, оконечная точка — Node.js и Express, машинное зрение — Keras, Tensorflow, Darknet/YoloV3 и Nvidia TensorRT.\r\n\r\nДля распознавания номерных знаков работает ALPR Unconstrained, для отслеживания лиц — Facenet. Обе программы свободно доступны на GitHub. Система также использует набор данных Google Open Images В качестве обучающих данных.\r\n\r\nДемо\r\n\r\n\r\n\r\nПерспективы\r\n\r\nЭто не простой мод для автомобиля Tesla. Вы же понимаете, что программу для видеонаблюдения можно использовать с любыми гаджетами интернета вещей, а таких устройств вокруг нас всё больше и больше. Грубо говоря, каждый человек может стать эдаким Большим Братом, разумеется, не выходя за рамки законодательного поля.\r\n\r\nВ планах Трумэна Кейна — реализовать удалённый просмотр картинки с видеокамер Tesla, подключить к системе сторонние видеорегистраторы, внедрить модуль распознавания людей по походке и возможность распознавания других объектов.\r\n\r\nАвтор уверен, что корпорации и правительства обязательно будут внедрять подобные технологии, а в ближайшие годы количество сомнительных систем видеонаблюдения и утечек конфиденциальной информации из этих систем взлетит до небес. Если кто-то захочет объединить такие устройства в единую систему, то это будет очень мощная система тотального наблюдения. Представьте, что к 146 000 стационарным видеокамерам на улицах Москвы подключатся ещё видеорегистраторы миллионов автомобилей.\r\n','2019-08-23 22:10:08',NULL,1);

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;
